{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constantes y Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Semilla\n",
    "SEED = 333\n",
    "\n",
    "# Preparamos el lematizado\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Lematizar un string\n",
    "import re\n",
    "def stemming_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "## Columnas de guardado para los algortimos \n",
    "COLUMNS = ['mean_fit_time','std_fit_time','mean_test_neg_log_loss','std_test_neg_log_loss','rank_test_neg_log_loss',\n",
    "           'mean_test_accuracy','rank_test_accuracy',\n",
    "           'mean_test_f1_macro','rank_test_f1_macro',\n",
    "           'mean_test_roc_auc_ovr','rank_test_roc_auc_ovr']\n",
    "\n",
    "# Funcion de guardado de resultados que es un subconjunto de cv_results. \n",
    "# Guarda los resultados de los parametros del algoritmo y las metricas que le pasamos como parametro.\n",
    "def save_results(rs,params_to_evaluate,columns=COLUMNS):\n",
    "    aux = pd.DataFrame(rs.cv_results_)\n",
    "    gs_res = pd.DataFrame()\n",
    "    for col in params_to_evaluate:\n",
    "        gs_res[col] = aux[col]\n",
    "    for col in columns:\n",
    "        gs_res[col] = aux[col]\n",
    "    return gs_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>3198</td>\n",
       "      <td>Inactivation of Ras GTPase activating proteins...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>2161</td>\n",
       "      <td>The PTEN (phosphatase and tensin homolog) phos...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>1083</td>\n",
       "      <td>EZH2, the catalytic subunit of the PRC2 comple...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>113</td>\n",
       "      <td>Endometrial cancer is the most common gynecolo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>885</td>\n",
       "      <td>Purpose: Platelet-derived growth factor recept...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>3210</td>\n",
       "      <td>Hereditary predisposition to retinoblastoma is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>153</td>\n",
       "      <td>Many studies have reported the EGFR mutations ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>2312</td>\n",
       "      <td>A systematic characterization of the genetic a...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>1107</td>\n",
       "      <td>Multiple endocrine neoplasia type 1 (MEN1, OM...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>1648</td>\n",
       "      <td>In acute myeloid leukemia (AML), two clusters ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               Text  Class\n",
       "3198  3198  Inactivation of Ras GTPase activating proteins...      1\n",
       "2161  2161  The PTEN (phosphatase and tensin homolog) phos...      4\n",
       "1083  1083  EZH2, the catalytic subunit of the PRC2 comple...      9\n",
       "113    113  Endometrial cancer is the most common gynecolo...      4\n",
       "885    885  Purpose: Platelet-derived growth factor recept...      7\n",
       "3210  3210  Hereditary predisposition to retinoblastoma is...      1\n",
       "153    153  Many studies have reported the EGFR mutations ...      2\n",
       "2312  2312  A systematic characterization of the genetic a...      7\n",
       "1107  1107   Multiple endocrine neoplasia type 1 (MEN1, OM...      4\n",
       "1648  1648  In acute myeloid leukemia (AML), two clusters ...      7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "train_variants_df = pd.read_csv(r\"C:\\Users\\Junio\\Libretas\\data-c\\training_variants\", engine='python')\n",
    "train_txt_df = pd.read_csv(r\"C:\\Users\\Junio\\Libretas\\data-c/training_text\", sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "train_txt_df['Class'] = train_variants_df['Class']\n",
    "train_txt_df.sample(10,random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparacion del Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_count</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>3343</td>\n",
       "      <td>1</td>\n",
       "      <td>Inactivation of Ras GTPase activating proteins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>3005</td>\n",
       "      <td>7</td>\n",
       "      <td>MYD88 L265P is a somatic mutation that has bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>11198</td>\n",
       "      <td>6</td>\n",
       "      <td>We describe the case of a patient presenting w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>19533</td>\n",
       "      <td>4</td>\n",
       "      <td>Endometrial cancer is the most common gynecolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>15135</td>\n",
       "      <td>7</td>\n",
       "      <td>Transforming mutations in NRAS and KRAS are th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>14851</td>\n",
       "      <td>1</td>\n",
       "      <td>Abstract Fanconi anemia is characterized by c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>3837</td>\n",
       "      <td>2</td>\n",
       "      <td>Many studies have reported the EGFR mutations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>65740</td>\n",
       "      <td>7</td>\n",
       "      <td>The development of array comparative genomic h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>6895</td>\n",
       "      <td>7</td>\n",
       "      <td>Over 30 mutations of the B-RAF gene associated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>10154</td>\n",
       "      <td>1</td>\n",
       "      <td>Tuberous sclerosis (TSC) is an autosomal domin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Text_count  Class                                               Text\n",
       "3198        3343      1  Inactivation of Ras GTPase activating proteins...\n",
       "2084        3005      7  MYD88 L265P is a somatic mutation that has bee...\n",
       "3185       11198      6  We describe the case of a patient presenting w...\n",
       "113        19533      4  Endometrial cancer is the most common gynecolo...\n",
       "3133       15135      7  Transforming mutations in NRAS and KRAS are th...\n",
       "1110       14851      1   Abstract Fanconi anemia is characterized by c...\n",
       "153         3837      2  Many studies have reported the EGFR mutations ...\n",
       "1242       65740      7  The development of array comparative genomic h...\n",
       "2768        6895      7  Over 30 mutations of the B-RAF gene associated...\n",
       "1045       10154      1  Tuberous sclerosis (TSC) is an autosomal domin..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializamos el dataframe que vamos a utilizar\n",
    "W = pd.DataFrame()\n",
    "\n",
    "# Añadimos una columna que nos indica el tamaño del texto de cada instancia\n",
    "W['Text_count']  = train_txt_df[\"Text\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Copiamos la clase y el texto\n",
    "W['Class'] = train_txt_df['Class'].copy()\n",
    "W['Text'] = train_txt_df[\"Text\"].copy()\n",
    "\n",
    "# Nos quedamos con las instancias que no tengan el texto nulo\n",
    "W = W[W['Text_count']!=1]\n",
    "\n",
    "# Mostramos el dataframe\n",
    "W.sample(10,random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparando la Clasificacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separacion training/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(W['Text'], W['Class'], test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando stop_words\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "# Capturando las palabras que no se encuentran en STOPWORDS por ser una contraccion de la palabra original (salida de stemming_tokenizer)\n",
    "contract_words = {'abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', \n",
    "              'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', \n",
    "              'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', \n",
    "              'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', \n",
    "              'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', \n",
    "              'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', \n",
    "              'someth', 'sometim', 'somewher', 'themselv', 'thenc', \n",
    "              'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', \n",
    "              'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', \n",
    "              'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'}\n",
    "\n",
    "l2 = {'anywh', 'aren', 'becau', 'couldn', 'd', 'didn', 'doe', \n",
    "      'doesn', 'don', 'el', 'elsewh', 'everywh', 'hadn', 'hasn', \n",
    "      'haven', 'ind', 'isn', 'let', 'll', 'm', 'mustn', \n",
    "      'otherwi', 'plea', 're', 's', 'shan', 'shouldn', \n",
    "      'somewh', 't', 've', 'wasn', 'weren', 'won', 'wouldn'}\n",
    "\n",
    "custom_words = {\"fig\", \"figure\", \"et\", \"al\", \"al.\", \"also\",\n",
    "                \"data\", \"analyze\", \"study\", \"table\", \"using\",\n",
    "                \"method\", \"result\", \"conclusion\", \"author\", \n",
    "                \"find\", \"found\", \"show\", \"casita\",\"non\",\"name\",\"image\",\n",
    "                'analyz', 'conclus', 'figur','conclu', 'imag', 'studi', 'tabl', 'use'}\n",
    "\n",
    "# Unimos ambas listas\n",
    "stop_words = STOPWORDS.union(contract_words).union(l2)\n",
    "\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "# Para crear pipelines de manera sencilla\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline\n",
    "def create_pipeline(clf,ngram_range=(1,1)):\n",
    "    tf_idf = TfidfVectorizer(analyzer=\"word\", tokenizer=stemming_tokenizer,stop_words= stop_words,ngram_range=ngram_range)\n",
    "    aumento = SMOTETomek(random_state=SEED)\n",
    "    estimator = clf\n",
    "    return make_pipeline(tf_idf,aumento,estimator)\n",
    "\n",
    "\n",
    "# Validacion Cruzada Stratificada(n_splits=3):\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "CV = StratifiedKFold(n_splits=3, random_state=SEED, shuffle=True)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "def create_rscv(pipeline,params,n_iterations = 10,scoring = [\"neg_log_loss\",\"accuracy\",\"f1_macro\",\"roc_auc_ovr\"],cv = CV):\n",
    "    return RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            params,\n",
    "            n_iter = n_iterations,\n",
    "            verbose = 1,\n",
    "            random_state = SEED,\n",
    "            cv = cv,\n",
    "            n_jobs = -1,\n",
    "            scoring = scoring,\n",
    "            refit = \"neg_log_loss\" \n",
    "            )\n",
    "# Importamos la metrica principal de evaluacion\n",
    "from sklearn import metrics\n",
    "\n",
    "# Dataframe de guardado del test\n",
    "df_results = pd.DataFrame(columns = [\"clf\",\"log_loss\",\"accuracy\",\"f1-macro\",\"ROC\"])\n",
    "\n",
    "# Funcion de guardado del resultado del test\n",
    "def add_res(clf,name,X_test = X_test):   \n",
    "    # Guardamos las predicciones\n",
    "    y_predict_proba = clf.predict_proba(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Guardamos los resultados de las distintas metricas\n",
    "    log_loss = metrics.log_loss(y_test,y_predict_proba)\n",
    "    acc = metrics.accuracy_score(y_test,y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "    roc = metrics.roc_auc_score(y_test,y_predict_proba,multi_class='ovr')\n",
    "    \n",
    "    # Actualizamos el dataframe\n",
    "    df_results.loc[len(df_results)]=[name,log_loss,acc,f1,roc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "parameters = {\n",
    "    'tfidfvectorizer__ngram_range': ((1, 1),(2, 2),(1,2)),\n",
    "    'tfidfvectorizer__use_idf': (True, False),\n",
    "    'tfidfvectorizer__max_features': (1000,2000,3000,4000,5000,6000,7000,8000,9000,None),\n",
    "    'tfidfvectorizer__norm': ('l1', 'l2')\n",
    " }\n",
    "pipeline = create_pipeline(clf)\n",
    "rs_NB_M = create_rscv(pipeline,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "rs_NB_M.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidfvectorizer__max_features</th>\n",
       "      <th>param_tfidfvectorizer__ngram_range</th>\n",
       "      <th>param_tfidfvectorizer__use_idf</th>\n",
       "      <th>param_tfidfvectorizer__norm</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>mean_test_roc_auc_ovr</th>\n",
       "      <th>rank_test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>1039.434027</td>\n",
       "      <td>18.850769</td>\n",
       "      <td>-1.391355</td>\n",
       "      <td>0.060023</td>\n",
       "      <td>1</td>\n",
       "      <td>0.539593</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>1059.400635</td>\n",
       "      <td>10.737122</td>\n",
       "      <td>-1.444794</td>\n",
       "      <td>0.057871</td>\n",
       "      <td>2</td>\n",
       "      <td>0.495098</td>\n",
       "      <td>2</td>\n",
       "      <td>0.413895</td>\n",
       "      <td>2</td>\n",
       "      <td>0.846698</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>997.131005</td>\n",
       "      <td>5.628674</td>\n",
       "      <td>-2.108364</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>3</td>\n",
       "      <td>0.413650</td>\n",
       "      <td>5</td>\n",
       "      <td>0.366663</td>\n",
       "      <td>5</td>\n",
       "      <td>0.849269</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>1007.245070</td>\n",
       "      <td>24.140710</td>\n",
       "      <td>-2.133374</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>4</td>\n",
       "      <td>0.417798</td>\n",
       "      <td>4</td>\n",
       "      <td>0.375975</td>\n",
       "      <td>4</td>\n",
       "      <td>0.848803</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>788.239446</td>\n",
       "      <td>147.878577</td>\n",
       "      <td>-2.137689</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>5</td>\n",
       "      <td>0.389140</td>\n",
       "      <td>7</td>\n",
       "      <td>0.360676</td>\n",
       "      <td>6</td>\n",
       "      <td>0.851932</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_tfidfvectorizer__max_features param_tfidfvectorizer__ngram_range  \\\n",
       "8                                5000                             (1, 1)   \n",
       "7                                1000                             (2, 2)   \n",
       "0                                3000                             (2, 2)   \n",
       "4                                5000                             (1, 1)   \n",
       "9                                6000                             (2, 2)   \n",
       "\n",
       "  param_tfidfvectorizer__use_idf param_tfidfvectorizer__norm  mean_fit_time  \\\n",
       "8                           True                          l2    1039.434027   \n",
       "7                           True                          l2    1059.400635   \n",
       "0                           True                          l1     997.131005   \n",
       "4                           True                          l1    1007.245070   \n",
       "9                           True                          l1     788.239446   \n",
       "\n",
       "   std_fit_time  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "8     18.850769               -1.391355               0.060023   \n",
       "7     10.737122               -1.444794               0.057871   \n",
       "0      5.628674               -2.108364               0.001107   \n",
       "4     24.140710               -2.133374               0.001456   \n",
       "9    147.878577               -2.137689               0.002027   \n",
       "\n",
       "   rank_test_neg_log_loss  mean_test_accuracy  rank_test_accuracy  \\\n",
       "8                       1            0.539593                   1   \n",
       "7                       2            0.495098                   2   \n",
       "0                       3            0.413650                   5   \n",
       "4                       4            0.417798                   4   \n",
       "9                       5            0.389140                   7   \n",
       "\n",
       "   mean_test_f1_macro  rank_test_f1_macro  mean_test_roc_auc_ovr  \\\n",
       "8            0.472142                   1               0.857517   \n",
       "7            0.413895                   2               0.846698   \n",
       "0            0.366663                   5               0.849269   \n",
       "4            0.375975                   4               0.848803   \n",
       "9            0.360676                   6               0.851932   \n",
       "\n",
       "   rank_test_roc_auc_ovr  \n",
       "8                      1  \n",
       "7                      7  \n",
       "0                      5  \n",
       "4                      6  \n",
       "9                      3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_evaluate = [\"param_tfidfvectorizer__max_features\",\"param_tfidfvectorizer__ngram_range\",\"param_tfidfvectorizer__use_idf\",\n",
    "                      \"param_tfidfvectorizer__norm\"]\n",
    "NB_M_res = save_results(rs_NB_M,params_to_evaluate)\n",
    "NB_M_res.sort_values(by='mean_test_neg_log_loss',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados\n",
    "NB_M_res.to_csv('NB_M.csv')\n",
    "\n",
    "# Testing\n",
    "add_res(rs_NB_M,'NB_M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "parameters = {\n",
    "    'tfidfvectorizer__ngram_range': ((1, 1),(2, 2),(1,2)),\n",
    "    'tfidfvectorizer__use_idf': (True, False),\n",
    "    'tfidfvectorizer__max_features': (1000,2000,3000,4000,5000,6000,7000,8000,9000,None),\n",
    "    'tfidfvectorizer__norm': ('l1', 'l2'),\n",
    "    'kneighborsclassifier__n_neighbors': tuple(range(1,60,2))\n",
    " }\n",
    "pipeline5 = create_pipeline(knn)\n",
    "rs_KNN = create_rscv(pipeline5,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 234.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=333, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('tfidfvectorizer',\n",
       "                                              TfidfVectorizer(stop_words={'a',\n",
       "                                                                          'about',\n",
       "                                                                          'abov',\n",
       "                                                                          'above',\n",
       "                                                                          'after',\n",
       "                                                                          'afterward',\n",
       "                                                                          'again',\n",
       "                                                                          'against',\n",
       "                                                                          'all',\n",
       "                                                                          'alon',\n",
       "                                                                          'alreadi',\n",
       "                                                                          'also',\n",
       "                                                                          'alway',\n",
       "                                                                          'am',\n",
       "                                                                          'an',\n",
       "                                                                          'and',\n",
       "                                                                          'ani',\n",
       "                                                                          'anoth',\n",
       "                                                                          'any',\n",
       "                                                                          'anyon',\n",
       "                                                                          'anyth',\n",
       "                                                                          'anywh',\n",
       "                                                                          'anywher',\n",
       "                                                                          'are',\n",
       "                                                                          'aren',\n",
       "                                                                          \"aren't\",\n",
       "                                                                          'a...\n",
       "                                                                              41,\n",
       "                                                                              43,\n",
       "                                                                              45,\n",
       "                                                                              47,\n",
       "                                                                              49,\n",
       "                                                                              51,\n",
       "                                                                              53,\n",
       "                                                                              55,\n",
       "                                                                              57,\n",
       "                                                                              59),\n",
       "                                        'tfidfvectorizer__max_features': (1000,\n",
       "                                                                          2000,\n",
       "                                                                          3000,\n",
       "                                                                          4000,\n",
       "                                                                          5000,\n",
       "                                                                          6000,\n",
       "                                                                          7000,\n",
       "                                                                          8000,\n",
       "                                                                          9000,\n",
       "                                                                          None),\n",
       "                                        'tfidfvectorizer__ngram_range': ((1, 1),\n",
       "                                                                         (2, 2),\n",
       "                                                                         (1,\n",
       "                                                                          2)),\n",
       "                                        'tfidfvectorizer__norm': ('l1', 'l2'),\n",
       "                                        'tfidfvectorizer__use_idf': (True,\n",
       "                                                                     False)},\n",
       "                   random_state=333, refit='neg_log_loss',\n",
       "                   scoring=['neg_log_loss', 'accuracy', 'f1_macro',\n",
       "                            'roc_auc_ovr'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_KNN.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidfvectorizer__max_features</th>\n",
       "      <th>param_tfidfvectorizer__ngram_range</th>\n",
       "      <th>param_tfidfvectorizer__use_idf</th>\n",
       "      <th>param_tfidfvectorizer__norm</th>\n",
       "      <th>param_kneighborsclassifier__n_neighbors</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>mean_test_roc_auc_ovr</th>\n",
       "      <th>rank_test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>59</td>\n",
       "      <td>926.378875</td>\n",
       "      <td>6.178383</td>\n",
       "      <td>-2.612732</td>\n",
       "      <td>0.301800</td>\n",
       "      <td>1</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>8</td>\n",
       "      <td>0.334451</td>\n",
       "      <td>6</td>\n",
       "      <td>0.816880</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>59</td>\n",
       "      <td>972.862212</td>\n",
       "      <td>7.849921</td>\n",
       "      <td>-3.072612</td>\n",
       "      <td>0.515209</td>\n",
       "      <td>2</td>\n",
       "      <td>0.290724</td>\n",
       "      <td>10</td>\n",
       "      <td>0.296639</td>\n",
       "      <td>9</td>\n",
       "      <td>0.825898</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>57</td>\n",
       "      <td>927.163444</td>\n",
       "      <td>6.515623</td>\n",
       "      <td>-3.717019</td>\n",
       "      <td>0.360032</td>\n",
       "      <td>3</td>\n",
       "      <td>0.297134</td>\n",
       "      <td>9</td>\n",
       "      <td>0.292893</td>\n",
       "      <td>10</td>\n",
       "      <td>0.814931</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>33</td>\n",
       "      <td>925.429747</td>\n",
       "      <td>5.687038</td>\n",
       "      <td>-3.826130</td>\n",
       "      <td>0.487326</td>\n",
       "      <td>4</td>\n",
       "      <td>0.353318</td>\n",
       "      <td>7</td>\n",
       "      <td>0.331658</td>\n",
       "      <td>7</td>\n",
       "      <td>0.829770</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>31</td>\n",
       "      <td>899.261407</td>\n",
       "      <td>10.545363</td>\n",
       "      <td>-3.846075</td>\n",
       "      <td>0.094189</td>\n",
       "      <td>5</td>\n",
       "      <td>0.366516</td>\n",
       "      <td>6</td>\n",
       "      <td>0.327754</td>\n",
       "      <td>8</td>\n",
       "      <td>0.815456</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_tfidfvectorizer__max_features param_tfidfvectorizer__ngram_range  \\\n",
       "7                                4000                             (1, 1)   \n",
       "8                                5000                             (1, 2)   \n",
       "4                                7000                             (2, 2)   \n",
       "3                                5000                             (1, 1)   \n",
       "0                                1000                             (2, 2)   \n",
       "\n",
       "  param_tfidfvectorizer__use_idf param_tfidfvectorizer__norm  \\\n",
       "7                           True                          l1   \n",
       "8                          False                          l2   \n",
       "4                           True                          l2   \n",
       "3                          False                          l2   \n",
       "0                           True                          l1   \n",
       "\n",
       "  param_kneighborsclassifier__n_neighbors  mean_fit_time  std_fit_time  \\\n",
       "7                                      59     926.378875      6.178383   \n",
       "8                                      59     972.862212      7.849921   \n",
       "4                                      57     927.163444      6.515623   \n",
       "3                                      33     925.429747      5.687038   \n",
       "0                                      31     899.261407     10.545363   \n",
       "\n",
       "   mean_test_neg_log_loss  std_test_neg_log_loss  rank_test_neg_log_loss  \\\n",
       "7               -2.612732               0.301800                       1   \n",
       "8               -3.072612               0.515209                       2   \n",
       "4               -3.717019               0.360032                       3   \n",
       "3               -3.826130               0.487326                       4   \n",
       "0               -3.846075               0.094189                       5   \n",
       "\n",
       "   mean_test_accuracy  rank_test_accuracy  mean_test_f1_macro  \\\n",
       "7            0.328054                   8            0.334451   \n",
       "8            0.290724                  10            0.296639   \n",
       "4            0.297134                   9            0.292893   \n",
       "3            0.353318                   7            0.331658   \n",
       "0            0.366516                   6            0.327754   \n",
       "\n",
       "   rank_test_f1_macro  mean_test_roc_auc_ovr  rank_test_roc_auc_ovr  \n",
       "7                   6               0.816880                      6  \n",
       "8                   9               0.825898                      4  \n",
       "4                  10               0.814931                      8  \n",
       "3                   7               0.829770                      3  \n",
       "0                   8               0.815456                      7  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_evaluate = [\"param_tfidfvectorizer__max_features\",\"param_tfidfvectorizer__ngram_range\",\"param_tfidfvectorizer__use_idf\",\n",
    "                      \"param_tfidfvectorizer__norm\",\"param_kneighborsclassifier__n_neighbors\"]\n",
    "KNN_res = save_results(rs_KNN,params_to_evaluate)\n",
    "KNN_res.sort_values(by='mean_test_neg_log_loss',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados\n",
    "KNN_res.to_csv('KNN.csv')\n",
    "\n",
    "# Testing\n",
    "add_res(rs_KNN,'KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf3 = RandomForestClassifier(random_state=SEED)\n",
    "parameters = {\n",
    "    'tfidfvectorizer__ngram_range': ((1, 1),(2, 2),(1,2)),\n",
    "    'tfidfvectorizer__use_idf': (True, False),\n",
    "    'tfidfvectorizer__max_features': (1000,2000,3000,4000,5000,6000,7000,8000,9000,None),\n",
    "    'tfidfvectorizer__norm': ('l1', 'l2'),\n",
    "    'randomforestclassifier__criterion':('giny','entropy')\n",
    " }\n",
    "pipeline3 = create_pipeline(clf3)\n",
    "rs_RF = create_rscv(pipeline3,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 182.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=333, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('tfidfvectorizer',\n",
       "                                              TfidfVectorizer(stop_words={'a',\n",
       "                                                                          'about',\n",
       "                                                                          'abov',\n",
       "                                                                          'above',\n",
       "                                                                          'after',\n",
       "                                                                          'afterward',\n",
       "                                                                          'again',\n",
       "                                                                          'against',\n",
       "                                                                          'all',\n",
       "                                                                          'alon',\n",
       "                                                                          'alreadi',\n",
       "                                                                          'also',\n",
       "                                                                          'alway',\n",
       "                                                                          'am',\n",
       "                                                                          'an',\n",
       "                                                                          'and',\n",
       "                                                                          'ani',\n",
       "                                                                          'anoth',\n",
       "                                                                          'any',\n",
       "                                                                          'anyon',\n",
       "                                                                          'anyth',\n",
       "                                                                          'anywh',\n",
       "                                                                          'anywher',\n",
       "                                                                          'are',\n",
       "                                                                          'aren',\n",
       "                                                                          \"aren't\",\n",
       "                                                                          'a...\n",
       "                   param_distributions={'randomforestclassifier__criterion': ('giny',\n",
       "                                                                              'entropy'),\n",
       "                                        'tfidfvectorizer__max_features': (1000,\n",
       "                                                                          2000,\n",
       "                                                                          3000,\n",
       "                                                                          4000,\n",
       "                                                                          5000,\n",
       "                                                                          6000,\n",
       "                                                                          7000,\n",
       "                                                                          8000,\n",
       "                                                                          9000,\n",
       "                                                                          None),\n",
       "                                        'tfidfvectorizer__ngram_range': ((1, 1),\n",
       "                                                                         (2, 2),\n",
       "                                                                         (1,\n",
       "                                                                          2)),\n",
       "                                        'tfidfvectorizer__norm': ('l1', 'l2'),\n",
       "                                        'tfidfvectorizer__use_idf': (True,\n",
       "                                                                     False)},\n",
       "                   random_state=333, refit='neg_log_loss',\n",
       "                   scoring=['neg_log_loss', 'accuracy', 'f1_macro',\n",
       "                            'roc_auc_ovr'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_RF.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidfvectorizer__max_features</th>\n",
       "      <th>param_tfidfvectorizer__ngram_range</th>\n",
       "      <th>param_tfidfvectorizer__use_idf</th>\n",
       "      <th>param_tfidfvectorizer__norm</th>\n",
       "      <th>param_randomforestclassifier__criterion</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>mean_test_roc_auc_ovr</th>\n",
       "      <th>rank_test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1061.978851</td>\n",
       "      <td>12.235525</td>\n",
       "      <td>-1.813907</td>\n",
       "      <td>0.100854</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620287</td>\n",
       "      <td>1</td>\n",
       "      <td>0.538971</td>\n",
       "      <td>2</td>\n",
       "      <td>0.870337</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1099.787059</td>\n",
       "      <td>13.298077</td>\n",
       "      <td>-1.856291</td>\n",
       "      <td>0.057779</td>\n",
       "      <td>2</td>\n",
       "      <td>0.610106</td>\n",
       "      <td>5</td>\n",
       "      <td>0.526712</td>\n",
       "      <td>5</td>\n",
       "      <td>0.866933</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1024.090189</td>\n",
       "      <td>6.346614</td>\n",
       "      <td>-1.866947</td>\n",
       "      <td>0.145397</td>\n",
       "      <td>3</td>\n",
       "      <td>0.614630</td>\n",
       "      <td>4</td>\n",
       "      <td>0.537213</td>\n",
       "      <td>3</td>\n",
       "      <td>0.859295</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>876.802809</td>\n",
       "      <td>96.948109</td>\n",
       "      <td>-1.948730</td>\n",
       "      <td>0.029698</td>\n",
       "      <td>4</td>\n",
       "      <td>0.618401</td>\n",
       "      <td>2</td>\n",
       "      <td>0.542822</td>\n",
       "      <td>1</td>\n",
       "      <td>0.858182</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1063.469198</td>\n",
       "      <td>7.682120</td>\n",
       "      <td>-1.979492</td>\n",
       "      <td>0.106470</td>\n",
       "      <td>5</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>3</td>\n",
       "      <td>0.533798</td>\n",
       "      <td>4</td>\n",
       "      <td>0.854093</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_tfidfvectorizer__max_features param_tfidfvectorizer__ngram_range  \\\n",
       "6                                5000                             (1, 1)   \n",
       "3                                9000                             (1, 1)   \n",
       "1                                2000                             (1, 1)   \n",
       "9                                1000                             (1, 2)   \n",
       "8                                4000                             (1, 1)   \n",
       "\n",
       "  param_tfidfvectorizer__use_idf param_tfidfvectorizer__norm  \\\n",
       "6                           True                          l2   \n",
       "3                          False                          l1   \n",
       "1                          False                          l2   \n",
       "9                           True                          l2   \n",
       "8                           True                          l1   \n",
       "\n",
       "  param_randomforestclassifier__criterion  mean_fit_time  std_fit_time  \\\n",
       "6                                 entropy    1061.978851     12.235525   \n",
       "3                                 entropy    1099.787059     13.298077   \n",
       "1                                 entropy    1024.090189      6.346614   \n",
       "9                                 entropy     876.802809     96.948109   \n",
       "8                                 entropy    1063.469198      7.682120   \n",
       "\n",
       "   mean_test_neg_log_loss  std_test_neg_log_loss  rank_test_neg_log_loss  \\\n",
       "6               -1.813907               0.100854                       1   \n",
       "3               -1.856291               0.057779                       2   \n",
       "1               -1.866947               0.145397                       3   \n",
       "9               -1.948730               0.029698                       4   \n",
       "8               -1.979492               0.106470                       5   \n",
       "\n",
       "   mean_test_accuracy  rank_test_accuracy  mean_test_f1_macro  \\\n",
       "6            0.620287                   1            0.538971   \n",
       "3            0.610106                   5            0.526712   \n",
       "1            0.614630                   4            0.537213   \n",
       "9            0.618401                   2            0.542822   \n",
       "8            0.617647                   3            0.533798   \n",
       "\n",
       "   rank_test_f1_macro  mean_test_roc_auc_ovr  rank_test_roc_auc_ovr  \n",
       "6                   2               0.870337                      1  \n",
       "3                   5               0.866933                      2  \n",
       "1                   3               0.859295                      3  \n",
       "9                   1               0.858182                      4  \n",
       "8                   4               0.854093                      5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_evaluate = [\"param_tfidfvectorizer__max_features\",\"param_tfidfvectorizer__ngram_range\",\"param_tfidfvectorizer__use_idf\",\n",
    "                      \"param_tfidfvectorizer__norm\",\"param_randomforestclassifier__criterion\"]\n",
    "RF_res = save_results(rs_RF,params_to_evaluate)\n",
    "RF_res.sort_values(by='mean_test_neg_log_loss',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados\n",
    "RF_res.to_csv('RF.csv')\n",
    "\n",
    "# Testing\n",
    "add_res(rs_RF,'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf4 = SVC(probability=True)\n",
    "parameters = {\n",
    "    'tfidfvectorizer__ngram_range': ((1, 1),(2, 2),(1,2)),\n",
    "    'tfidfvectorizer__use_idf': (True, False),\n",
    "    'tfidfvectorizer__max_features': (1000,2000,3000,4000,5000,6000,7000,8000,9000,None),\n",
    "    'tfidfvectorizer__norm': ('l1', 'l2'),\n",
    "    'svc__kernel':('linear','rbf','sigmoid','poly')\n",
    " }\n",
    "pipeline4 = create_pipeline(clf4)\n",
    "rs_SVC = create_rscv(pipeline4,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 573.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=333, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('tfidfvectorizer',\n",
       "                                              TfidfVectorizer(stop_words={'a',\n",
       "                                                                          'about',\n",
       "                                                                          'abov',\n",
       "                                                                          'above',\n",
       "                                                                          'after',\n",
       "                                                                          'afterward',\n",
       "                                                                          'again',\n",
       "                                                                          'against',\n",
       "                                                                          'all',\n",
       "                                                                          'alon',\n",
       "                                                                          'alreadi',\n",
       "                                                                          'also',\n",
       "                                                                          'alway',\n",
       "                                                                          'am',\n",
       "                                                                          'an',\n",
       "                                                                          'and',\n",
       "                                                                          'ani',\n",
       "                                                                          'anoth',\n",
       "                                                                          'any',\n",
       "                                                                          'anyon',\n",
       "                                                                          'anyth',\n",
       "                                                                          'anywh',\n",
       "                                                                          'anywher',\n",
       "                                                                          'are',\n",
       "                                                                          'aren',\n",
       "                                                                          \"aren't\",\n",
       "                                                                          'a...\n",
       "                   param_distributions={'svc__kernel': ('linear', 'rbf',\n",
       "                                                        'sigmoid', 'poly'),\n",
       "                                        'tfidfvectorizer__max_features': (1000,\n",
       "                                                                          2000,\n",
       "                                                                          3000,\n",
       "                                                                          4000,\n",
       "                                                                          5000,\n",
       "                                                                          6000,\n",
       "                                                                          7000,\n",
       "                                                                          8000,\n",
       "                                                                          9000,\n",
       "                                                                          None),\n",
       "                                        'tfidfvectorizer__ngram_range': ((1, 1),\n",
       "                                                                         (2, 2),\n",
       "                                                                         (1,\n",
       "                                                                          2)),\n",
       "                                        'tfidfvectorizer__norm': ('l1', 'l2'),\n",
       "                                        'tfidfvectorizer__use_idf': (True,\n",
       "                                                                     False)},\n",
       "                   random_state=333, refit='neg_log_loss',\n",
       "                   scoring=['neg_log_loss', 'accuracy', 'f1_macro',\n",
       "                            'roc_auc_ovr'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_SVC.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidfvectorizer__max_features</th>\n",
       "      <th>param_tfidfvectorizer__use_idf</th>\n",
       "      <th>param_tfidfvectorizer__ngram_range</th>\n",
       "      <th>param_tfidfvectorizer__norm</th>\n",
       "      <th>param_svc__kernel</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>mean_test_roc_auc_ovr</th>\n",
       "      <th>rank_test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>l2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1594.243199</td>\n",
       "      <td>8.100563</td>\n",
       "      <td>-1.144969</td>\n",
       "      <td>0.032005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.624811</td>\n",
       "      <td>1</td>\n",
       "      <td>0.543988</td>\n",
       "      <td>1</td>\n",
       "      <td>0.883414</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>l2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2068.816854</td>\n",
       "      <td>4.556349</td>\n",
       "      <td>-1.150726</td>\n",
       "      <td>0.021940</td>\n",
       "      <td>2</td>\n",
       "      <td>0.620664</td>\n",
       "      <td>2</td>\n",
       "      <td>0.535051</td>\n",
       "      <td>2</td>\n",
       "      <td>0.891259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5000</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>l2</td>\n",
       "      <td>linear</td>\n",
       "      <td>1836.320048</td>\n",
       "      <td>7.236467</td>\n",
       "      <td>-1.174417</td>\n",
       "      <td>0.032429</td>\n",
       "      <td>3</td>\n",
       "      <td>0.594268</td>\n",
       "      <td>4</td>\n",
       "      <td>0.528394</td>\n",
       "      <td>3</td>\n",
       "      <td>0.878716</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7000</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>l2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1841.263618</td>\n",
       "      <td>15.566603</td>\n",
       "      <td>-1.194646</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>4</td>\n",
       "      <td>0.578054</td>\n",
       "      <td>6</td>\n",
       "      <td>0.501365</td>\n",
       "      <td>8</td>\n",
       "      <td>0.883805</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9000</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>l2</td>\n",
       "      <td>poly</td>\n",
       "      <td>2856.092859</td>\n",
       "      <td>39.370383</td>\n",
       "      <td>-1.235021</td>\n",
       "      <td>0.028726</td>\n",
       "      <td>5</td>\n",
       "      <td>0.607466</td>\n",
       "      <td>3</td>\n",
       "      <td>0.527783</td>\n",
       "      <td>5</td>\n",
       "      <td>0.880646</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_tfidfvectorizer__max_features param_tfidfvectorizer__use_idf  \\\n",
       "3                                5000                           True   \n",
       "1                                7000                           True   \n",
       "7                                5000                          False   \n",
       "8                                7000                           True   \n",
       "6                                9000                           True   \n",
       "\n",
       "  param_tfidfvectorizer__ngram_range param_tfidfvectorizer__norm  \\\n",
       "3                             (2, 2)                          l2   \n",
       "1                             (1, 1)                          l2   \n",
       "7                             (1, 1)                          l2   \n",
       "8                             (1, 1)                          l2   \n",
       "6                             (1, 2)                          l2   \n",
       "\n",
       "  param_svc__kernel  mean_fit_time  std_fit_time  mean_test_neg_log_loss  \\\n",
       "3               rbf    1594.243199      8.100563               -1.144969   \n",
       "1               rbf    2068.816854      4.556349               -1.150726   \n",
       "7            linear    1836.320048      7.236467               -1.174417   \n",
       "8           sigmoid    1841.263618     15.566603               -1.194646   \n",
       "6              poly    2856.092859     39.370383               -1.235021   \n",
       "\n",
       "   std_test_neg_log_loss  rank_test_neg_log_loss  mean_test_accuracy  \\\n",
       "3               0.032005                       1            0.624811   \n",
       "1               0.021940                       2            0.620664   \n",
       "7               0.032429                       3            0.594268   \n",
       "8               0.009901                       4            0.578054   \n",
       "6               0.028726                       5            0.607466   \n",
       "\n",
       "   rank_test_accuracy  mean_test_f1_macro  rank_test_f1_macro  \\\n",
       "3                   1            0.543988                   1   \n",
       "1                   2            0.535051                   2   \n",
       "7                   4            0.528394                   3   \n",
       "8                   6            0.501365                   8   \n",
       "6                   3            0.527783                   5   \n",
       "\n",
       "   mean_test_roc_auc_ovr  rank_test_roc_auc_ovr  \n",
       "3               0.883414                      3  \n",
       "1               0.891259                      1  \n",
       "7               0.878716                      5  \n",
       "8               0.883805                      2  \n",
       "6               0.880646                      4  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_evaluate = [\"param_tfidfvectorizer__max_features\",\"param_tfidfvectorizer__use_idf\",\"param_tfidfvectorizer__ngram_range\",\"param_tfidfvectorizer__norm\",\"param_svc__kernel\"]\n",
    "SVC_res = save_results(rs_SVC,params_to_evaluate)\n",
    "SVC_res.sort_values(by='mean_test_neg_log_loss',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados\n",
    "SVC_res.to_csv('SVC.csv')\n",
    "\n",
    "# Testing\n",
    "add_res(rs_SVC,'SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB_M</td>\n",
       "      <td>1.458101</td>\n",
       "      <td>0.509036</td>\n",
       "      <td>0.446943</td>\n",
       "      <td>0.828397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>2.813324</td>\n",
       "      <td>0.356928</td>\n",
       "      <td>0.365564</td>\n",
       "      <td>0.819434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>1.851255</td>\n",
       "      <td>0.596386</td>\n",
       "      <td>0.556653</td>\n",
       "      <td>0.863149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1.227287</td>\n",
       "      <td>0.600904</td>\n",
       "      <td>0.531162</td>\n",
       "      <td>0.879490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clf  log_loss  accuracy  f1-macro       ROC\n",
       "0  NB_M  1.458101  0.509036  0.446943  0.828397\n",
       "1   KNN  2.813324  0.356928  0.365564  0.819434\n",
       "2    RF  1.851255  0.596386  0.556653  0.863149\n",
       "3   SVC  1.227287  0.600904  0.531162  0.879490"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exportamos resultados totales\n",
    "df_results.to_csv('df_rs.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
