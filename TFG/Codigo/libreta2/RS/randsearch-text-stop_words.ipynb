{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constantes y Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Semilla\n",
    "SEED = 333\n",
    "\n",
    "# Preparamos el lematizado\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Lematizar un string\n",
    "import re\n",
    "def stemming_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "## Columnas de guardado para los algortimos \n",
    "COLUMNS = ['mean_fit_time','std_fit_time','mean_test_neg_log_loss','std_test_neg_log_loss','rank_test_neg_log_loss',\n",
    "           'mean_test_accuracy','rank_test_accuracy',\n",
    "           'mean_test_f1_macro','rank_test_f1_macro',\n",
    "           'mean_test_roc_auc_ovr','rank_test_roc_auc_ovr']\n",
    "\n",
    "# Funcion de guardado de resultados que es un subconjunto de cv_results. \n",
    "# Guarda los resultados de los parametros del algoritmo y las metricas que le pasamos como parametro.\n",
    "def save_results(rs,params_to_evaluate,columns=COLUMNS):\n",
    "    aux = pd.DataFrame(rs.cv_results_)\n",
    "    gs_res = pd.DataFrame()\n",
    "    for col in params_to_evaluate:\n",
    "        gs_res[col] = aux[col]\n",
    "    for col in columns:\n",
    "        gs_res[col] = aux[col]\n",
    "    return gs_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>3198</td>\n",
       "      <td>Inactivation of Ras GTPase activating proteins...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>2161</td>\n",
       "      <td>The PTEN (phosphatase and tensin homolog) phos...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>1083</td>\n",
       "      <td>EZH2, the catalytic subunit of the PRC2 comple...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>113</td>\n",
       "      <td>Endometrial cancer is the most common gynecolo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>885</td>\n",
       "      <td>Purpose: Platelet-derived growth factor recept...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>3210</td>\n",
       "      <td>Hereditary predisposition to retinoblastoma is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>153</td>\n",
       "      <td>Many studies have reported the EGFR mutations ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>2312</td>\n",
       "      <td>A systematic characterization of the genetic a...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>1107</td>\n",
       "      <td>Multiple endocrine neoplasia type 1 (MEN1, OM...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>1648</td>\n",
       "      <td>In acute myeloid leukemia (AML), two clusters ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               Text  Class\n",
       "3198  3198  Inactivation of Ras GTPase activating proteins...      1\n",
       "2161  2161  The PTEN (phosphatase and tensin homolog) phos...      4\n",
       "1083  1083  EZH2, the catalytic subunit of the PRC2 comple...      9\n",
       "113    113  Endometrial cancer is the most common gynecolo...      4\n",
       "885    885  Purpose: Platelet-derived growth factor recept...      7\n",
       "3210  3210  Hereditary predisposition to retinoblastoma is...      1\n",
       "153    153  Many studies have reported the EGFR mutations ...      2\n",
       "2312  2312  A systematic characterization of the genetic a...      7\n",
       "1107  1107   Multiple endocrine neoplasia type 1 (MEN1, OM...      4\n",
       "1648  1648  In acute myeloid leukemia (AML), two clusters ...      7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "train_variants_df = pd.read_csv(r\"C:\\Users\\Junio\\Libretas\\data-c\\training_variants\", engine='python')\n",
    "train_txt_df = pd.read_csv(r\"C:\\Users\\Junio\\Libretas\\data-c/training_text\", sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "train_txt_df['Class'] = train_variants_df['Class']\n",
    "train_txt_df.sample(10,random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparacion del Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_count</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>3343</td>\n",
       "      <td>1</td>\n",
       "      <td>Inactivation of Ras GTPase activating proteins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>3005</td>\n",
       "      <td>7</td>\n",
       "      <td>MYD88 L265P is a somatic mutation that has bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>11198</td>\n",
       "      <td>6</td>\n",
       "      <td>We describe the case of a patient presenting w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>19533</td>\n",
       "      <td>4</td>\n",
       "      <td>Endometrial cancer is the most common gynecolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>15135</td>\n",
       "      <td>7</td>\n",
       "      <td>Transforming mutations in NRAS and KRAS are th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>14851</td>\n",
       "      <td>1</td>\n",
       "      <td>Abstract Fanconi anemia is characterized by c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>3837</td>\n",
       "      <td>2</td>\n",
       "      <td>Many studies have reported the EGFR mutations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>65740</td>\n",
       "      <td>7</td>\n",
       "      <td>The development of array comparative genomic h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>6895</td>\n",
       "      <td>7</td>\n",
       "      <td>Over 30 mutations of the B-RAF gene associated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>10154</td>\n",
       "      <td>1</td>\n",
       "      <td>Tuberous sclerosis (TSC) is an autosomal domin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Text_count  Class                                               Text\n",
       "3198        3343      1  Inactivation of Ras GTPase activating proteins...\n",
       "2084        3005      7  MYD88 L265P is a somatic mutation that has bee...\n",
       "3185       11198      6  We describe the case of a patient presenting w...\n",
       "113        19533      4  Endometrial cancer is the most common gynecolo...\n",
       "3133       15135      7  Transforming mutations in NRAS and KRAS are th...\n",
       "1110       14851      1   Abstract Fanconi anemia is characterized by c...\n",
       "153         3837      2  Many studies have reported the EGFR mutations ...\n",
       "1242       65740      7  The development of array comparative genomic h...\n",
       "2768        6895      7  Over 30 mutations of the B-RAF gene associated...\n",
       "1045       10154      1  Tuberous sclerosis (TSC) is an autosomal domin..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializamos el dataframe que vamos a utilizar\n",
    "W = pd.DataFrame()\n",
    "\n",
    "# Añadimos una columna que nos indica el tamaño del texto de cada instancia\n",
    "W['Text_count']  = train_txt_df[\"Text\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Copiamos la clase y el texto\n",
    "W['Class'] = train_txt_df['Class'].copy()\n",
    "W['Text'] = train_txt_df[\"Text\"].copy()\n",
    "\n",
    "# Nos quedamos con las instancias que no tengan el texto nulo\n",
    "W = W[W['Text_count']!=1]\n",
    "\n",
    "# Mostramos el dataframe\n",
    "W.sample(10,random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparando la Clasificacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separacion training/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(W['Text'], W['Class'], test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando stop_words\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "# Capturando las palabras que no se encuentran en STOPWORDS por ser una contraccion de la palabra original (salida de stemming_tokenizer)\n",
    "contract_words = {'abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', \n",
    "              'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', \n",
    "              'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', \n",
    "              'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', \n",
    "              'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', \n",
    "              'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', \n",
    "              'someth', 'sometim', 'somewher', 'themselv', 'thenc', \n",
    "              'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', \n",
    "              'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', \n",
    "              'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'}\n",
    "\n",
    "l2 = {'anywh', 'aren', 'becau', 'couldn', 'd', 'didn', 'doe', \n",
    "      'doesn', 'don', 'el', 'elsewh', 'everywh', 'hadn', 'hasn', \n",
    "      'haven', 'ind', 'isn', 'let', 'll', 'm', 'mustn', \n",
    "      'otherwi', 'plea', 're', 's', 'shan', 'shouldn', \n",
    "      'somewh', 't', 've', 'wasn', 'weren', 'won', 'wouldn'}\n",
    "\n",
    "custom_words = {\"fig\", \"figure\", \"et\", \"al\", \"al.\", \"also\",\n",
    "                \"data\", \"analyze\", \"study\", \"table\", \"using\",\n",
    "                \"method\", \"result\", \"conclusion\", \"author\", \n",
    "                \"find\", \"found\", \"show\", \"casita\",\"non\",\"name\",\"image\",\n",
    "                'analyz', 'conclus', 'figur','conclu', 'imag', 'studi', 'tabl', 'use'}\n",
    "# Unimos ambas listas\n",
    "stop_words = STOPWORDS.union(contract_words).union(l2)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "def create_pipeline(clf,ngram_range=(1,1)):\n",
    "    return Pipeline([('tfidf', TfidfVectorizer(analyzer=\"word\", tokenizer=stemming_tokenizer,stop_words= stop_words,ngram_range=ngram_range)),\n",
    "                         ('clf', clf)])\n",
    "\n",
    "\n",
    "# Validacion Cruzada Stratificada(n_splits=3):\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "CV = StratifiedKFold(n_splits=3, random_state=SEED, shuffle=True)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "def create_rscv(pipeline,params,n_iterations = 10,scoring = [\"neg_log_loss\",\"accuracy\",\"f1_macro\",\"roc_auc_ovr\"],cv = CV):\n",
    "    return RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            params,\n",
    "            n_iter = n_iterations,\n",
    "            verbose = 1,\n",
    "            random_state = SEED,\n",
    "            cv = cv,\n",
    "            n_jobs = -1,\n",
    "            scoring = scoring,\n",
    "            refit = \"neg_log_loss\" \n",
    "            )\n",
    "# Importamos la metrica principal de evaluacion\n",
    "from sklearn import metrics\n",
    "\n",
    "# Dataframe de guardado del test\n",
    "df_results = pd.DataFrame(columns = [\"clf\",\"log_loss\",\"accuracy\",\"f1-macro\",\"ROC\"])\n",
    "\n",
    "# Funcion de guardado del resultado del test\n",
    "def add_res(clf,name,X_test = X_test):   \n",
    "    # Guardamos las predicciones\n",
    "    y_predict_proba = clf.predict_proba(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Guardamos los resultados de las distintas metricas\n",
    "    log_loss = metrics.log_loss(y_test,y_predict_proba)\n",
    "    acc = metrics.accuracy_score(y_test,y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "    roc = metrics.roc_auc_score(y_test,y_predict_proba,multi_class='ovr')\n",
    "    \n",
    "    # Actualizamos el dataframe\n",
    "    df_results.loc[len(df_results)]=[name,log_loss,acc,f1,roc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1, 1),(2, 2),(1,2)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__max_features': (1000,2000,3000,4000,5000,6000,7000,8000,9000,None),\n",
    "    'tfidf__norm': ('l1', 'l2')\n",
    " }\n",
    "pipeline = create_pipeline(clf)\n",
    "rs_NB_M = create_rscv(pipeline,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 238.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=333, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('tfidf',\n",
       "                                              TfidfVectorizer(stop_words={'a',\n",
       "                                                                          'about',\n",
       "                                                                          'abov',\n",
       "                                                                          'above',\n",
       "                                                                          'after',\n",
       "                                                                          'afterward',\n",
       "                                                                          'again',\n",
       "                                                                          'against',\n",
       "                                                                          'all',\n",
       "                                                                          'alon',\n",
       "                                                                          'alreadi',\n",
       "                                                                          'also',\n",
       "                                                                          'alway',\n",
       "                                                                          'am',\n",
       "                                                                          'an',\n",
       "                                                                          'and',\n",
       "                                                                          'ani',\n",
       "                                                                          'anoth',\n",
       "                                                                          'any',\n",
       "                                                                          'anyon',\n",
       "                                                                          'anyth',\n",
       "                                                                          'anywh',\n",
       "                                                                          'anywher',\n",
       "                                                                          'are',\n",
       "                                                                          'aren',\n",
       "                                                                          \"aren't\",\n",
       "                                                                          'as',\n",
       "                                                                          'at',\n",
       "                                                                          'b...\n",
       "                                                              tokenizer=<function stemming_tokenizer at 0x0000024CF52DAA60>)),\n",
       "                                             ('clf', MultinomialNB())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'tfidf__max_features': (1000, 2000,\n",
       "                                                                3000, 4000,\n",
       "                                                                5000, 6000,\n",
       "                                                                7000, 8000,\n",
       "                                                                9000, None),\n",
       "                                        'tfidf__ngram_range': ((1, 1), (2, 2),\n",
       "                                                               (1, 2)),\n",
       "                                        'tfidf__norm': ('l1', 'l2'),\n",
       "                                        'tfidf__use_idf': (True, False)},\n",
       "                   random_state=333, refit='neg_log_loss',\n",
       "                   scoring=['neg_log_loss', 'accuracy', 'f1_macro',\n",
       "                            'roc_auc_ovr'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_NB_M.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidf__max_features</th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_tfidf__norm</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>mean_test_roc_auc_ovr</th>\n",
       "      <th>rank_test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>842.279479</td>\n",
       "      <td>6.601352</td>\n",
       "      <td>-1.304260</td>\n",
       "      <td>0.010437</td>\n",
       "      <td>1</td>\n",
       "      <td>0.535445</td>\n",
       "      <td>2</td>\n",
       "      <td>0.328068</td>\n",
       "      <td>1</td>\n",
       "      <td>0.830213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>810.378766</td>\n",
       "      <td>6.940436</td>\n",
       "      <td>-1.460152</td>\n",
       "      <td>0.040744</td>\n",
       "      <td>2</td>\n",
       "      <td>0.538839</td>\n",
       "      <td>1</td>\n",
       "      <td>0.297690</td>\n",
       "      <td>2</td>\n",
       "      <td>0.801549</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>841.407810</td>\n",
       "      <td>10.784107</td>\n",
       "      <td>-1.778819</td>\n",
       "      <td>0.003577</td>\n",
       "      <td>3</td>\n",
       "      <td>0.299397</td>\n",
       "      <td>3</td>\n",
       "      <td>0.066202</td>\n",
       "      <td>3</td>\n",
       "      <td>0.745292</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>1016.755881</td>\n",
       "      <td>8.411149</td>\n",
       "      <td>-1.793446</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>4</td>\n",
       "      <td>0.282428</td>\n",
       "      <td>4</td>\n",
       "      <td>0.048940</td>\n",
       "      <td>4</td>\n",
       "      <td>0.782798</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>751.402773</td>\n",
       "      <td>71.727727</td>\n",
       "      <td>-1.797094</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>5</td>\n",
       "      <td>0.282428</td>\n",
       "      <td>4</td>\n",
       "      <td>0.048940</td>\n",
       "      <td>4</td>\n",
       "      <td>0.761074</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_tfidf__max_features param_tfidf__ngram_range param_tfidf__use_idf  \\\n",
       "7                      1000                   (2, 2)                 True   \n",
       "8                      5000                   (1, 1)                 True   \n",
       "0                      3000                   (2, 2)                 True   \n",
       "4                      5000                   (1, 1)                 True   \n",
       "9                      6000                   (2, 2)                 True   \n",
       "\n",
       "  param_tfidf__norm  mean_fit_time  std_fit_time  mean_test_neg_log_loss  \\\n",
       "7                l2     842.279479      6.601352               -1.304260   \n",
       "8                l2     810.378766      6.940436               -1.460152   \n",
       "0                l1     841.407810     10.784107               -1.778819   \n",
       "4                l1    1016.755881      8.411149               -1.793446   \n",
       "9                l1     751.402773     71.727727               -1.797094   \n",
       "\n",
       "   std_test_neg_log_loss  rank_test_neg_log_loss  mean_test_accuracy  \\\n",
       "7               0.010437                       1            0.535445   \n",
       "8               0.040744                       2            0.538839   \n",
       "0               0.003577                       3            0.299397   \n",
       "4               0.003256                       4            0.282428   \n",
       "9               0.003284                       5            0.282428   \n",
       "\n",
       "   rank_test_accuracy  mean_test_f1_macro  rank_test_f1_macro  \\\n",
       "7                   2            0.328068                   1   \n",
       "8                   1            0.297690                   2   \n",
       "0                   3            0.066202                   3   \n",
       "4                   4            0.048940                   4   \n",
       "9                   4            0.048940                   4   \n",
       "\n",
       "   mean_test_roc_auc_ovr  rank_test_roc_auc_ovr  \n",
       "7               0.830213                      1  \n",
       "8               0.801549                      2  \n",
       "0               0.745292                      7  \n",
       "4               0.782798                      4  \n",
       "9               0.761074                      6  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_evaluate = [\"param_tfidf__max_features\",\"param_tfidf__ngram_range\",\"param_tfidf__use_idf\",\n",
    "                      \"param_tfidf__norm\"]\n",
    "NB_M_res = save_results(rs_NB_M,params_to_evaluate)\n",
    "NB_M_res.sort_values(by='mean_test_neg_log_loss',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados\n",
    "NB_M_res.to_csv('NB_M.csv')\n",
    "\n",
    "# Testing\n",
    "add_res(rs_NB_M,'NB_M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "clf2 = ComplementNB()\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1, 1),(2, 2),(1,2)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__max_features': (1000,2000,3000,4000,5000,6000,7000,8000,9000,None),\n",
    "    'tfidf__norm': ('l1', 'l2')\n",
    " }\n",
    "pipeline2 = create_pipeline(clf2)\n",
    "rs_NB_C = create_rscv(pipeline2,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 257.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=333, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('tfidf',\n",
       "                                              TfidfVectorizer(stop_words={'a',\n",
       "                                                                          'about',\n",
       "                                                                          'abov',\n",
       "                                                                          'above',\n",
       "                                                                          'after',\n",
       "                                                                          'afterward',\n",
       "                                                                          'again',\n",
       "                                                                          'against',\n",
       "                                                                          'all',\n",
       "                                                                          'alon',\n",
       "                                                                          'alreadi',\n",
       "                                                                          'also',\n",
       "                                                                          'alway',\n",
       "                                                                          'am',\n",
       "                                                                          'an',\n",
       "                                                                          'and',\n",
       "                                                                          'ani',\n",
       "                                                                          'anoth',\n",
       "                                                                          'any',\n",
       "                                                                          'anyon',\n",
       "                                                                          'anyth',\n",
       "                                                                          'anywh',\n",
       "                                                                          'anywher',\n",
       "                                                                          'are',\n",
       "                                                                          'aren',\n",
       "                                                                          \"aren't\",\n",
       "                                                                          'as',\n",
       "                                                                          'at',\n",
       "                                                                          'b...\n",
       "                                                              tokenizer=<function stemming_tokenizer at 0x0000024CF52DAA60>)),\n",
       "                                             ('clf', ComplementNB())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'tfidf__max_features': (1000, 2000,\n",
       "                                                                3000, 4000,\n",
       "                                                                5000, 6000,\n",
       "                                                                7000, 8000,\n",
       "                                                                9000, None),\n",
       "                                        'tfidf__ngram_range': ((1, 1), (2, 2),\n",
       "                                                               (1, 2)),\n",
       "                                        'tfidf__norm': ('l1', 'l2'),\n",
       "                                        'tfidf__use_idf': (True, False)},\n",
       "                   random_state=333, refit='neg_log_loss',\n",
       "                   scoring=['neg_log_loss', 'accuracy', 'f1_macro',\n",
       "                            'roc_auc_ovr'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_NB_C.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidf__max_features</th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_tfidf__norm</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>mean_test_roc_auc_ovr</th>\n",
       "      <th>rank_test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>903.699222</td>\n",
       "      <td>8.549372</td>\n",
       "      <td>-1.583684</td>\n",
       "      <td>0.006781</td>\n",
       "      <td>1</td>\n",
       "      <td>0.595023</td>\n",
       "      <td>1</td>\n",
       "      <td>0.451671</td>\n",
       "      <td>1</td>\n",
       "      <td>0.851182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>1051.410870</td>\n",
       "      <td>6.113063</td>\n",
       "      <td>-1.729723</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>2</td>\n",
       "      <td>0.533183</td>\n",
       "      <td>4</td>\n",
       "      <td>0.333714</td>\n",
       "      <td>5</td>\n",
       "      <td>0.834278</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>1049.933705</td>\n",
       "      <td>5.517039</td>\n",
       "      <td>-2.151305</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>3</td>\n",
       "      <td>0.552036</td>\n",
       "      <td>3</td>\n",
       "      <td>0.394429</td>\n",
       "      <td>3</td>\n",
       "      <td>0.826113</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>1035.710302</td>\n",
       "      <td>30.535763</td>\n",
       "      <td>-2.153315</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>4</td>\n",
       "      <td>0.362745</td>\n",
       "      <td>9</td>\n",
       "      <td>0.109663</td>\n",
       "      <td>9</td>\n",
       "      <td>0.805810</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>1012.452565</td>\n",
       "      <td>3.826718</td>\n",
       "      <td>-2.155405</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>5</td>\n",
       "      <td>0.519608</td>\n",
       "      <td>7</td>\n",
       "      <td>0.286583</td>\n",
       "      <td>7</td>\n",
       "      <td>0.842265</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_tfidf__max_features param_tfidf__ngram_range param_tfidf__use_idf  \\\n",
       "8                      5000                   (1, 1)                 True   \n",
       "7                      1000                   (2, 2)                 True   \n",
       "0                      3000                   (2, 2)                 True   \n",
       "6                      8000                   (1, 1)                False   \n",
       "2                      9000                   (1, 1)                 True   \n",
       "\n",
       "  param_tfidf__norm  mean_fit_time  std_fit_time  mean_test_neg_log_loss  \\\n",
       "8                l2     903.699222      8.549372               -1.583684   \n",
       "7                l2    1051.410870      6.113063               -1.729723   \n",
       "0                l1    1049.933705      5.517039               -2.151305   \n",
       "6                l1    1035.710302     30.535763               -2.153315   \n",
       "2                l1    1012.452565      3.826718               -2.155405   \n",
       "\n",
       "   std_test_neg_log_loss  rank_test_neg_log_loss  mean_test_accuracy  \\\n",
       "8               0.006781                       1            0.595023   \n",
       "7               0.002472                       2            0.533183   \n",
       "0               0.000111                       3            0.552036   \n",
       "6               0.000049                       4            0.362745   \n",
       "2               0.000202                       5            0.519608   \n",
       "\n",
       "   rank_test_accuracy  mean_test_f1_macro  rank_test_f1_macro  \\\n",
       "8                   1            0.451671                   1   \n",
       "7                   4            0.333714                   5   \n",
       "0                   3            0.394429                   3   \n",
       "6                   9            0.109663                   9   \n",
       "2                   7            0.286583                   7   \n",
       "\n",
       "   mean_test_roc_auc_ovr  rank_test_roc_auc_ovr  \n",
       "8               0.851182                      1  \n",
       "7               0.834278                      4  \n",
       "0               0.826113                      7  \n",
       "6               0.805810                      9  \n",
       "2               0.842265                      2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_evaluate = [\"param_tfidf__max_features\",\"param_tfidf__ngram_range\",\"param_tfidf__use_idf\",\n",
    "                      \"param_tfidf__norm\"]\n",
    "NB_C_res = save_results(rs_NB_C,params_to_evaluate)\n",
    "NB_C_res.sort_values(by='mean_test_neg_log_loss',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados\n",
    "NB_C_res.to_csv('NB_C.csv')\n",
    "\n",
    "# Testing\n",
    "add_res(rs_NB_C,'NB_C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1, 1),(2, 2),(1,2)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__max_features': (1000,2000,3000,4000,5000,6000,7000,8000,9000,None),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__n_neighbors': tuple(range(1,60,2))\n",
    " }\n",
    "pipeline5 = create_pipeline(knn)\n",
    "rs_KNN = create_rscv(pipeline5,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 232.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=333, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('tfidf',\n",
       "                                              TfidfVectorizer(stop_words={'a',\n",
       "                                                                          'about',\n",
       "                                                                          'abov',\n",
       "                                                                          'above',\n",
       "                                                                          'after',\n",
       "                                                                          'afterward',\n",
       "                                                                          'again',\n",
       "                                                                          'against',\n",
       "                                                                          'all',\n",
       "                                                                          'alon',\n",
       "                                                                          'alreadi',\n",
       "                                                                          'also',\n",
       "                                                                          'alway',\n",
       "                                                                          'am',\n",
       "                                                                          'an',\n",
       "                                                                          'and',\n",
       "                                                                          'ani',\n",
       "                                                                          'anoth',\n",
       "                                                                          'any',\n",
       "                                                                          'anyon',\n",
       "                                                                          'anyth',\n",
       "                                                                          'anywh',\n",
       "                                                                          'anywher',\n",
       "                                                                          'are',\n",
       "                                                                          'aren',\n",
       "                                                                          \"aren't\",\n",
       "                                                                          'as',\n",
       "                                                                          'at',\n",
       "                                                                          'b...\n",
       "                                                             13, 15, 17, 19, 21,\n",
       "                                                             23, 25, 27, 29, 31,\n",
       "                                                             33, 35, 37, 39, 41,\n",
       "                                                             43, 45, 47, 49, 51,\n",
       "                                                             53, 55, 57, 59),\n",
       "                                        'tfidf__max_features': (1000, 2000,\n",
       "                                                                3000, 4000,\n",
       "                                                                5000, 6000,\n",
       "                                                                7000, 8000,\n",
       "                                                                9000, None),\n",
       "                                        'tfidf__ngram_range': ((1, 1), (2, 2),\n",
       "                                                               (1, 2)),\n",
       "                                        'tfidf__norm': ('l1', 'l2'),\n",
       "                                        'tfidf__use_idf': (True, False)},\n",
       "                   random_state=333, refit='neg_log_loss',\n",
       "                   scoring=['neg_log_loss', 'accuracy', 'f1_macro',\n",
       "                            'roc_auc_ovr'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_KNN.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidf__max_features</th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_tfidf__norm</th>\n",
       "      <th>param_clf__n_neighbors</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>mean_test_roc_auc_ovr</th>\n",
       "      <th>rank_test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>59</td>\n",
       "      <td>860.185606</td>\n",
       "      <td>5.795864</td>\n",
       "      <td>-1.665384</td>\n",
       "      <td>0.053852</td>\n",
       "      <td>1</td>\n",
       "      <td>0.478884</td>\n",
       "      <td>7</td>\n",
       "      <td>0.275628</td>\n",
       "      <td>8</td>\n",
       "      <td>0.818245</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>57</td>\n",
       "      <td>1000.285799</td>\n",
       "      <td>9.171289</td>\n",
       "      <td>-1.775546</td>\n",
       "      <td>0.116579</td>\n",
       "      <td>2</td>\n",
       "      <td>0.476621</td>\n",
       "      <td>9</td>\n",
       "      <td>0.258317</td>\n",
       "      <td>9</td>\n",
       "      <td>0.829799</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>33</td>\n",
       "      <td>937.439335</td>\n",
       "      <td>7.433932</td>\n",
       "      <td>-1.973448</td>\n",
       "      <td>0.090360</td>\n",
       "      <td>3</td>\n",
       "      <td>0.493967</td>\n",
       "      <td>6</td>\n",
       "      <td>0.304978</td>\n",
       "      <td>6</td>\n",
       "      <td>0.831315</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>59</td>\n",
       "      <td>817.203187</td>\n",
       "      <td>5.248160</td>\n",
       "      <td>-2.019685</td>\n",
       "      <td>0.083152</td>\n",
       "      <td>4</td>\n",
       "      <td>0.430241</td>\n",
       "      <td>10</td>\n",
       "      <td>0.230764</td>\n",
       "      <td>10</td>\n",
       "      <td>0.808625</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>25</td>\n",
       "      <td>854.041332</td>\n",
       "      <td>45.037448</td>\n",
       "      <td>-2.188570</td>\n",
       "      <td>0.133254</td>\n",
       "      <td>5</td>\n",
       "      <td>0.519985</td>\n",
       "      <td>4</td>\n",
       "      <td>0.359224</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_tfidf__max_features param_tfidf__ngram_range param_tfidf__use_idf  \\\n",
       "8                      5000                   (1, 2)                False   \n",
       "4                      7000                   (2, 2)                 True   \n",
       "3                      5000                   (1, 1)                False   \n",
       "7                      4000                   (1, 1)                 True   \n",
       "2                      1000                   (1, 1)                False   \n",
       "\n",
       "  param_tfidf__norm param_clf__n_neighbors  mean_fit_time  std_fit_time  \\\n",
       "8                l2                     59     860.185606      5.795864   \n",
       "4                l2                     57    1000.285799      9.171289   \n",
       "3                l2                     33     937.439335      7.433932   \n",
       "7                l1                     59     817.203187      5.248160   \n",
       "2                l2                     25     854.041332     45.037448   \n",
       "\n",
       "   mean_test_neg_log_loss  std_test_neg_log_loss  rank_test_neg_log_loss  \\\n",
       "8               -1.665384               0.053852                       1   \n",
       "4               -1.775546               0.116579                       2   \n",
       "3               -1.973448               0.090360                       3   \n",
       "7               -2.019685               0.083152                       4   \n",
       "2               -2.188570               0.133254                       5   \n",
       "\n",
       "   mean_test_accuracy  rank_test_accuracy  mean_test_f1_macro  \\\n",
       "8            0.478884                   7            0.275628   \n",
       "4            0.476621                   9            0.258317   \n",
       "3            0.493967                   6            0.304978   \n",
       "7            0.430241                  10            0.230764   \n",
       "2            0.519985                   4            0.359224   \n",
       "\n",
       "   rank_test_f1_macro  mean_test_roc_auc_ovr  rank_test_roc_auc_ovr  \n",
       "8                   8               0.818245                      6  \n",
       "4                   9               0.829799                      3  \n",
       "3                   6               0.831315                      2  \n",
       "7                  10               0.808625                      8  \n",
       "2                   5               0.833732                      1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_evaluate = [\"param_tfidf__max_features\",\"param_tfidf__ngram_range\",\"param_tfidf__use_idf\",\n",
    "                      \"param_tfidf__norm\",\"param_clf__n_neighbors\"]\n",
    "KNN_res = save_results(rs_KNN,params_to_evaluate)\n",
    "KNN_res.sort_values(by='mean_test_neg_log_loss',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados\n",
    "KNN_res.to_csv('KNN.csv')\n",
    "\n",
    "# Testing\n",
    "add_res(rs_KNN,'KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf3 = RandomForestClassifier(random_state=SEED)\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1, 1),(2, 2),(1,2)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__max_features': (1000,2000,3000,4000,5000,6000,7000,8000,9000,None),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__criterion':('giny','entropy')\n",
    " }\n",
    "pipeline3 = create_pipeline(clf3)\n",
    "rs_RF = create_rscv(pipeline3,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 163.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=333, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('tfidf',\n",
       "                                              TfidfVectorizer(stop_words={'a',\n",
       "                                                                          'about',\n",
       "                                                                          'abov',\n",
       "                                                                          'above',\n",
       "                                                                          'after',\n",
       "                                                                          'afterward',\n",
       "                                                                          'again',\n",
       "                                                                          'against',\n",
       "                                                                          'all',\n",
       "                                                                          'alon',\n",
       "                                                                          'alreadi',\n",
       "                                                                          'also',\n",
       "                                                                          'alway',\n",
       "                                                                          'am',\n",
       "                                                                          'an',\n",
       "                                                                          'and',\n",
       "                                                                          'ani',\n",
       "                                                                          'anoth',\n",
       "                                                                          'any',\n",
       "                                                                          'anyon',\n",
       "                                                                          'anyth',\n",
       "                                                                          'anywh',\n",
       "                                                                          'anywher',\n",
       "                                                                          'are',\n",
       "                                                                          'aren',\n",
       "                                                                          \"aren't\",\n",
       "                                                                          'as',\n",
       "                                                                          'at',\n",
       "                                                                          'b...\n",
       "                                              RandomForestClassifier(random_state=333))]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'clf__criterion': ('giny', 'entropy'),\n",
       "                                        'tfidf__max_features': (1000, 2000,\n",
       "                                                                3000, 4000,\n",
       "                                                                5000, 6000,\n",
       "                                                                7000, 8000,\n",
       "                                                                9000, None),\n",
       "                                        'tfidf__ngram_range': ((1, 1), (2, 2),\n",
       "                                                               (1, 2)),\n",
       "                                        'tfidf__norm': ('l1', 'l2'),\n",
       "                                        'tfidf__use_idf': (True, False)},\n",
       "                   random_state=333, refit='neg_log_loss',\n",
       "                   scoring=['neg_log_loss', 'accuracy', 'f1_macro',\n",
       "                            'roc_auc_ovr'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_RF.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidf__max_features</th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_tfidf__norm</th>\n",
       "      <th>param_clf__criterion</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>mean_test_roc_auc_ovr</th>\n",
       "      <th>rank_test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>782.512933</td>\n",
       "      <td>66.025566</td>\n",
       "      <td>-1.664640</td>\n",
       "      <td>0.077941</td>\n",
       "      <td>1</td>\n",
       "      <td>0.635370</td>\n",
       "      <td>2</td>\n",
       "      <td>0.502398</td>\n",
       "      <td>2</td>\n",
       "      <td>0.873852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>855.589561</td>\n",
       "      <td>6.132000</td>\n",
       "      <td>-1.667135</td>\n",
       "      <td>0.037609</td>\n",
       "      <td>2</td>\n",
       "      <td>0.631599</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500690</td>\n",
       "      <td>4</td>\n",
       "      <td>0.862489</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>861.420969</td>\n",
       "      <td>7.764854</td>\n",
       "      <td>-1.671802</td>\n",
       "      <td>0.110835</td>\n",
       "      <td>3</td>\n",
       "      <td>0.636124</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504538</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870616</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>850.762133</td>\n",
       "      <td>3.939272</td>\n",
       "      <td>-1.691484</td>\n",
       "      <td>0.084461</td>\n",
       "      <td>4</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500036</td>\n",
       "      <td>5</td>\n",
       "      <td>0.869830</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>880.478687</td>\n",
       "      <td>9.337633</td>\n",
       "      <td>-1.711282</td>\n",
       "      <td>0.121392</td>\n",
       "      <td>5</td>\n",
       "      <td>0.631599</td>\n",
       "      <td>3</td>\n",
       "      <td>0.501721</td>\n",
       "      <td>3</td>\n",
       "      <td>0.876962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_tfidf__max_features param_tfidf__ngram_range param_tfidf__use_idf  \\\n",
       "9                      1000                   (1, 2)                 True   \n",
       "6                      5000                   (1, 1)                 True   \n",
       "8                      4000                   (1, 1)                 True   \n",
       "1                      2000                   (1, 1)                False   \n",
       "3                      9000                   (1, 1)                False   \n",
       "\n",
       "  param_tfidf__norm param_clf__criterion  mean_fit_time  std_fit_time  \\\n",
       "9                l2              entropy     782.512933     66.025566   \n",
       "6                l2              entropy     855.589561      6.132000   \n",
       "8                l1              entropy     861.420969      7.764854   \n",
       "1                l2              entropy     850.762133      3.939272   \n",
       "3                l1              entropy     880.478687      9.337633   \n",
       "\n",
       "   mean_test_neg_log_loss  std_test_neg_log_loss  rank_test_neg_log_loss  \\\n",
       "9               -1.664640               0.077941                       1   \n",
       "6               -1.667135               0.037609                       2   \n",
       "8               -1.671802               0.110835                       3   \n",
       "1               -1.691484               0.084461                       4   \n",
       "3               -1.711282               0.121392                       5   \n",
       "\n",
       "   mean_test_accuracy  rank_test_accuracy  mean_test_f1_macro  \\\n",
       "9            0.635370                   2            0.502398   \n",
       "6            0.631599                   3            0.500690   \n",
       "8            0.636124                   1            0.504538   \n",
       "1            0.628205                   5            0.500036   \n",
       "3            0.631599                   3            0.501721   \n",
       "\n",
       "   rank_test_f1_macro  mean_test_roc_auc_ovr  rank_test_roc_auc_ovr  \n",
       "9                   2               0.873852                      2  \n",
       "6                   4               0.862489                      5  \n",
       "8                   1               0.870616                      3  \n",
       "1                   5               0.869830                      4  \n",
       "3                   3               0.876962                      1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_evaluate = [\"param_tfidf__max_features\",\"param_tfidf__ngram_range\",\"param_tfidf__use_idf\",\n",
    "                      \"param_tfidf__norm\",\"param_clf__criterion\"]\n",
    "RF_res = save_results(rs_RF,params_to_evaluate)\n",
    "RF_res.sort_values(by='mean_test_neg_log_loss',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados\n",
    "RF_res.to_csv('RF.csv')\n",
    "\n",
    "# Testing\n",
    "add_res(rs_RF,'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf4 = SVC(probability=True)\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1, 1),(2, 2),(1,2)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__max_features': (1000,2000,3000,4000,5000,6000,7000,8000,9000,None),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__kernel':('linear','rbf','sigmoid','poly')\n",
    " }\n",
    "pipeline4 = create_pipeline(clf4)\n",
    "rs_SVC = create_rscv(pipeline4,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 279.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=333, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('tfidf',\n",
       "                                              TfidfVectorizer(stop_words={'a',\n",
       "                                                                          'about',\n",
       "                                                                          'abov',\n",
       "                                                                          'above',\n",
       "                                                                          'after',\n",
       "                                                                          'afterward',\n",
       "                                                                          'again',\n",
       "                                                                          'against',\n",
       "                                                                          'all',\n",
       "                                                                          'alon',\n",
       "                                                                          'alreadi',\n",
       "                                                                          'also',\n",
       "                                                                          'alway',\n",
       "                                                                          'am',\n",
       "                                                                          'an',\n",
       "                                                                          'and',\n",
       "                                                                          'ani',\n",
       "                                                                          'anoth',\n",
       "                                                                          'any',\n",
       "                                                                          'anyon',\n",
       "                                                                          'anyth',\n",
       "                                                                          'anywh',\n",
       "                                                                          'anywher',\n",
       "                                                                          'are',\n",
       "                                                                          'aren',\n",
       "                                                                          \"aren't\",\n",
       "                                                                          'as',\n",
       "                                                                          'at',\n",
       "                                                                          'b...\n",
       "                   param_distributions={'clf__kernel': ('linear', 'rbf',\n",
       "                                                        'sigmoid', 'poly'),\n",
       "                                        'tfidf__max_features': (1000, 2000,\n",
       "                                                                3000, 4000,\n",
       "                                                                5000, 6000,\n",
       "                                                                7000, 8000,\n",
       "                                                                9000, None),\n",
       "                                        'tfidf__ngram_range': ((1, 1), (2, 2),\n",
       "                                                               (1, 2)),\n",
       "                                        'tfidf__norm': ('l1', 'l2'),\n",
       "                                        'tfidf__use_idf': (True, False)},\n",
       "                   random_state=333, refit='neg_log_loss',\n",
       "                   scoring=['neg_log_loss', 'accuracy', 'f1_macro',\n",
       "                            'roc_auc_ovr'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_SVC.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidf__max_features</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "      <th>param_tfidf__norm</th>\n",
       "      <th>param_clf__kernel</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>mean_test_roc_auc_ovr</th>\n",
       "      <th>rank_test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>l2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1178.656833</td>\n",
       "      <td>12.020918</td>\n",
       "      <td>-1.059184</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>1</td>\n",
       "      <td>0.625189</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497468</td>\n",
       "      <td>1</td>\n",
       "      <td>0.893184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>l2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1036.365253</td>\n",
       "      <td>11.086397</td>\n",
       "      <td>-1.059470</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>2</td>\n",
       "      <td>0.624057</td>\n",
       "      <td>2</td>\n",
       "      <td>0.492285</td>\n",
       "      <td>3</td>\n",
       "      <td>0.892005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9000</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>l2</td>\n",
       "      <td>poly</td>\n",
       "      <td>1429.277459</td>\n",
       "      <td>9.088498</td>\n",
       "      <td>-1.078076</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>3</td>\n",
       "      <td>0.615762</td>\n",
       "      <td>3</td>\n",
       "      <td>0.493106</td>\n",
       "      <td>2</td>\n",
       "      <td>0.890569</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5000</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>l2</td>\n",
       "      <td>linear</td>\n",
       "      <td>1033.692731</td>\n",
       "      <td>10.363156</td>\n",
       "      <td>-1.086370</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>4</td>\n",
       "      <td>0.612745</td>\n",
       "      <td>4</td>\n",
       "      <td>0.467052</td>\n",
       "      <td>4</td>\n",
       "      <td>0.880357</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7000</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>l2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1079.909835</td>\n",
       "      <td>9.782600</td>\n",
       "      <td>-1.109774</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>5</td>\n",
       "      <td>0.602187</td>\n",
       "      <td>5</td>\n",
       "      <td>0.448780</td>\n",
       "      <td>5</td>\n",
       "      <td>0.879036</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_tfidf__max_features param_tfidf__use_idf param_tfidf__ngram_range  \\\n",
       "1                      7000                 True                   (1, 1)   \n",
       "3                      5000                 True                   (2, 2)   \n",
       "6                      9000                 True                   (1, 2)   \n",
       "7                      5000                False                   (1, 1)   \n",
       "8                      7000                 True                   (1, 1)   \n",
       "\n",
       "  param_tfidf__norm param_clf__kernel  mean_fit_time  std_fit_time  \\\n",
       "1                l2               rbf    1178.656833     12.020918   \n",
       "3                l2               rbf    1036.365253     11.086397   \n",
       "6                l2              poly    1429.277459      9.088498   \n",
       "7                l2            linear    1033.692731     10.363156   \n",
       "8                l2           sigmoid    1079.909835      9.782600   \n",
       "\n",
       "   mean_test_neg_log_loss  std_test_neg_log_loss  rank_test_neg_log_loss  \\\n",
       "1               -1.059184               0.006116                       1   \n",
       "3               -1.059470               0.009264                       2   \n",
       "6               -1.078076               0.004070                       3   \n",
       "7               -1.086370               0.022727                       4   \n",
       "8               -1.109774               0.007586                       5   \n",
       "\n",
       "   mean_test_accuracy  rank_test_accuracy  mean_test_f1_macro  \\\n",
       "1            0.625189                   1            0.497468   \n",
       "3            0.624057                   2            0.492285   \n",
       "6            0.615762                   3            0.493106   \n",
       "7            0.612745                   4            0.467052   \n",
       "8            0.602187                   5            0.448780   \n",
       "\n",
       "   rank_test_f1_macro  mean_test_roc_auc_ovr  rank_test_roc_auc_ovr  \n",
       "1                   1               0.893184                      1  \n",
       "3                   3               0.892005                      2  \n",
       "6                   2               0.890569                      3  \n",
       "7                   4               0.880357                      4  \n",
       "8                   5               0.879036                      5  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_evaluate = [\"param_tfidf__max_features\",\"param_tfidf__use_idf\",\"param_tfidf__ngram_range\",\"param_tfidf__norm\",\"param_clf__kernel\"]\n",
    "SVC_res = save_results(rs_SVC,params_to_evaluate)\n",
    "SVC_res.sort_values(by='mean_test_neg_log_loss',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados\n",
    "SVC_res.to_csv('SVC.csv')\n",
    "\n",
    "# Testing\n",
    "add_res(rs_SVC,'SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB_M</td>\n",
       "      <td>1.339528</td>\n",
       "      <td>0.552711</td>\n",
       "      <td>0.336474</td>\n",
       "      <td>0.802195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB_C</td>\n",
       "      <td>1.565477</td>\n",
       "      <td>0.591867</td>\n",
       "      <td>0.427967</td>\n",
       "      <td>0.838728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>1.669148</td>\n",
       "      <td>0.504518</td>\n",
       "      <td>0.282924</td>\n",
       "      <td>0.829964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>1.460784</td>\n",
       "      <td>0.612952</td>\n",
       "      <td>0.531519</td>\n",
       "      <td>0.883515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1.033469</td>\n",
       "      <td>0.637048</td>\n",
       "      <td>0.503059</td>\n",
       "      <td>0.890707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clf  log_loss  accuracy  f1-macro       ROC\n",
       "0  NB_M  1.339528  0.552711  0.336474  0.802195\n",
       "1  NB_C  1.565477  0.591867  0.427967  0.838728\n",
       "2   KNN  1.669148  0.504518  0.282924  0.829964\n",
       "3    RF  1.460784  0.612952  0.531519  0.883515\n",
       "4   SVC  1.033469  0.637048  0.503059  0.890707"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exportamos resultados totales\n",
    "df_results.to_csv('df_rs.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
