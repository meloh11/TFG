{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constantes y Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Semilla\n",
    "SEED = 333\n",
    "\n",
    "# Preparamos el lematizado\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Lematizar un string\n",
    "import re\n",
    "def stemming_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "## Columnas de guardado para los algortimos \n",
    "COLUMNS = ['mean_fit_time','std_fit_time','mean_test_neg_log_loss','std_test_neg_log_loss','rank_test_neg_log_loss',\n",
    "           'mean_test_accuracy','rank_test_accuracy',\n",
    "           'mean_test_f1_macro','rank_test_f1_macro',\n",
    "           'mean_test_roc_auc_ovr','rank_test_roc_auc_ovr']\n",
    "\n",
    "# Funcion de guardado de resultados que es un subconjunto de cv_results. \n",
    "# Guarda los resultados de los parametros del algoritmo y las metricas que le pasamos como parametro.\n",
    "def save_results(rs,params_to_evaluate,columns=COLUMNS):\n",
    "    aux = pd.DataFrame(rs.cv_results_)\n",
    "    gs_res = pd.DataFrame()\n",
    "    for col in params_to_evaluate:\n",
    "        gs_res[col] = aux[col]\n",
    "    for col in columns:\n",
    "        gs_res[col] = aux[col]\n",
    "    return gs_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>3198</td>\n",
       "      <td>Inactivation of Ras GTPase activating proteins...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>2161</td>\n",
       "      <td>The PTEN (phosphatase and tensin homolog) phos...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>1083</td>\n",
       "      <td>EZH2, the catalytic subunit of the PRC2 comple...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>113</td>\n",
       "      <td>Endometrial cancer is the most common gynecolo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>885</td>\n",
       "      <td>Purpose: Platelet-derived growth factor recept...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>3210</td>\n",
       "      <td>Hereditary predisposition to retinoblastoma is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>153</td>\n",
       "      <td>Many studies have reported the EGFR mutations ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>2312</td>\n",
       "      <td>A systematic characterization of the genetic a...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>1107</td>\n",
       "      <td>Multiple endocrine neoplasia type 1 (MEN1, OM...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>1648</td>\n",
       "      <td>In acute myeloid leukemia (AML), two clusters ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               Text  Class\n",
       "3198  3198  Inactivation of Ras GTPase activating proteins...      1\n",
       "2161  2161  The PTEN (phosphatase and tensin homolog) phos...      4\n",
       "1083  1083  EZH2, the catalytic subunit of the PRC2 comple...      9\n",
       "113    113  Endometrial cancer is the most common gynecolo...      4\n",
       "885    885  Purpose: Platelet-derived growth factor recept...      7\n",
       "3210  3210  Hereditary predisposition to retinoblastoma is...      1\n",
       "153    153  Many studies have reported the EGFR mutations ...      2\n",
       "2312  2312  A systematic characterization of the genetic a...      7\n",
       "1107  1107   Multiple endocrine neoplasia type 1 (MEN1, OM...      4\n",
       "1648  1648  In acute myeloid leukemia (AML), two clusters ...      7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "train_variants_df = pd.read_csv(r\"C:\\Users\\Junio\\Libretas\\data-c\\training_variants\", engine='python')\n",
    "train_txt_df = pd.read_csv(r\"C:\\Users\\Junio\\Libretas\\data-c/training_text\", sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "train_txt_df['Class'] = train_variants_df['Class']\n",
    "train_txt_df.sample(10,random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparacion del Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_count</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>3343</td>\n",
       "      <td>1</td>\n",
       "      <td>Inactivation of Ras GTPase activating proteins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>3005</td>\n",
       "      <td>7</td>\n",
       "      <td>MYD88 L265P is a somatic mutation that has bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>11198</td>\n",
       "      <td>6</td>\n",
       "      <td>We describe the case of a patient presenting w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>19533</td>\n",
       "      <td>4</td>\n",
       "      <td>Endometrial cancer is the most common gynecolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>15135</td>\n",
       "      <td>7</td>\n",
       "      <td>Transforming mutations in NRAS and KRAS are th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>14851</td>\n",
       "      <td>1</td>\n",
       "      <td>Abstract Fanconi anemia is characterized by c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>3837</td>\n",
       "      <td>2</td>\n",
       "      <td>Many studies have reported the EGFR mutations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>65740</td>\n",
       "      <td>7</td>\n",
       "      <td>The development of array comparative genomic h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>6895</td>\n",
       "      <td>7</td>\n",
       "      <td>Over 30 mutations of the B-RAF gene associated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>10154</td>\n",
       "      <td>1</td>\n",
       "      <td>Tuberous sclerosis (TSC) is an autosomal domin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Text_count  Class                                               Text\n",
       "3198        3343      1  Inactivation of Ras GTPase activating proteins...\n",
       "2084        3005      7  MYD88 L265P is a somatic mutation that has bee...\n",
       "3185       11198      6  We describe the case of a patient presenting w...\n",
       "113        19533      4  Endometrial cancer is the most common gynecolo...\n",
       "3133       15135      7  Transforming mutations in NRAS and KRAS are th...\n",
       "1110       14851      1   Abstract Fanconi anemia is characterized by c...\n",
       "153         3837      2  Many studies have reported the EGFR mutations ...\n",
       "1242       65740      7  The development of array comparative genomic h...\n",
       "2768        6895      7  Over 30 mutations of the B-RAF gene associated...\n",
       "1045       10154      1  Tuberous sclerosis (TSC) is an autosomal domin..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializamos el dataframe que vamos a utilizar\n",
    "W = pd.DataFrame()\n",
    "\n",
    "# Añadimos una columna que nos indica el tamaño del texto de cada instancia\n",
    "W['Text_count']  = train_txt_df[\"Text\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Copiamos la clase y el texto\n",
    "W['Class'] = train_txt_df['Class'].copy()\n",
    "W['Text'] = train_txt_df[\"Text\"].copy()\n",
    "\n",
    "# Nos quedamos con las instancias que no tengan el texto nulo\n",
    "W = W[W['Text_count']!=1]\n",
    "\n",
    "# Mostramos el dataframe\n",
    "W.sample(10,random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparando la Clasificacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separacion training/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(W['Text'], W['Class'], test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando stop_words\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "# Capturando las palabras que no se encuentran en STOPWORDS por ser una contraccion de la palabra original (salida de stemming_tokenizer)\n",
    "contract_words = {'abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', \n",
    "              'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', \n",
    "              'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', \n",
    "              'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', \n",
    "              'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', \n",
    "              'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', \n",
    "              'someth', 'sometim', 'somewher', 'themselv', 'thenc', \n",
    "              'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', \n",
    "              'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', \n",
    "              'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'}\n",
    "\n",
    "l2 = {'anywh', 'aren', 'becau', 'couldn', 'd', 'didn', 'doe', \n",
    "      'doesn', 'don', 'el', 'elsewh', 'everywh', 'hadn', 'hasn', \n",
    "      'haven', 'ind', 'isn', 'let', 'll', 'm', 'mustn', \n",
    "      'otherwi', 'plea', 're', 's', 'shan', 'shouldn', \n",
    "      'somewh', 't', 've', 'wasn', 'weren', 'won', 'wouldn'}\n",
    "\n",
    "custom_words = {\"fig\", \"figure\", \"et\", \"al\", \"al.\", \"also\",\n",
    "                \"data\", \"analyze\", \"study\", \"table\", \"using\",\n",
    "                \"method\", \"result\", \"conclusion\", \"author\", \n",
    "                \"find\", \"found\", \"show\", \"casita\",\"non\",\"name\",\"image\",\n",
    "                'analyz', 'conclus', 'figur','conclu', 'imag', 'studi', 'tabl', 'use'}\n",
    "# Unimos ambas listas\n",
    "stop_words = STOPWORDS.union(contract_words).union(l2).union(custom_words)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.feature_selection import RFECV\n",
    "#from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def create_pipeline(clf):\n",
    "    return Pipeline([('tfidf', TfidfVectorizer(analyzer=\"word\", tokenizer=stemming_tokenizer,stop_words= stop_words,max_features=1000)),\n",
    "                     ('sel',SelectKBest(chi2, k=100)),\n",
    "                     ('clf', clf)])\n",
    "\n",
    "\n",
    "# Validacion Cruzada Stratificada(n_splits=3):\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "CV = StratifiedKFold(n_splits=3, random_state=SEED, shuffle=True)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "def create_rscv(pipeline,params,n_iterations = 10,scoring = [\"neg_log_loss\",\"accuracy\",\"f1_macro\",\"roc_auc_ovr\"],cv = CV):\n",
    "    return RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            params,\n",
    "            n_iter = n_iterations,\n",
    "            verbose = 1,\n",
    "            random_state = SEED,\n",
    "            cv = cv,\n",
    "            n_jobs = -1,\n",
    "            scoring = scoring,\n",
    "            refit = \"neg_log_loss\" \n",
    "            )\n",
    "# Importamos la metrica principal de evaluacion\n",
    "from sklearn import metrics\n",
    "\n",
    "# Dataframe de guardado del test\n",
    "df_results = pd.DataFrame(columns = [\"clf\",\"log_loss\",\"accuracy\",\"f1-macro\",\"ROC\"])\n",
    "\n",
    "# Funcion de guardado del resultado del test\n",
    "def add_res(clf,name,X_test = X_test):   \n",
    "    # Guardamos las predicciones\n",
    "    y_predict_proba = clf.predict_proba(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Guardamos los resultados de las distintas metricas\n",
    "    log_loss = metrics.log_loss(y_test,y_predict_proba)\n",
    "    acc = metrics.accuracy_score(y_test,y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "    roc = metrics.roc_auc_score(y_test,y_predict_proba,multi_class='ovr')\n",
    "    \n",
    "    # Actualizamos el dataframe\n",
    "    df_results.loc[len(df_results)]=[name,log_loss,acc,f1,roc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://towardsdatascience.com/how-to-get-feature-importances-from-any-sklearn-pipeline-167a19f1214\n",
    "\n",
    "* https://towardsdatascience.com/the-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530\n",
    "\n",
    "* https://towardsdatascience.com/text-analysis-feature-engineering-with-nlp-502d6ea9225d\n",
    "\n",
    "* https://towardsdatascience.com/feature-selection-on-text-classification-1b86879f548e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1, 1),(2, 2),(1,2)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2')\n",
    " }\n",
    "pipeline = create_pipeline(clf)\n",
    "rs_NB_M = create_rscv(pipeline,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 222.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=333, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('tfidf',\n",
       "                                              TfidfVectorizer(max_features=1000,\n",
       "                                                              stop_words={'a',\n",
       "                                                                          'about',\n",
       "                                                                          'abov',\n",
       "                                                                          'above',\n",
       "                                                                          'after',\n",
       "                                                                          'afterward',\n",
       "                                                                          'again',\n",
       "                                                                          'against',\n",
       "                                                                          'al',\n",
       "                                                                          'al.',\n",
       "                                                                          'all',\n",
       "                                                                          'alon',\n",
       "                                                                          'alreadi',\n",
       "                                                                          'also',\n",
       "                                                                          'alway',\n",
       "                                                                          'am',\n",
       "                                                                          'an',\n",
       "                                                                          'analyz',\n",
       "                                                                          'analyze',\n",
       "                                                                          'and',\n",
       "                                                                          'ani',\n",
       "                                                                          'anoth',\n",
       "                                                                          'any',\n",
       "                                                                          'anyon',\n",
       "                                                                          'anyth',\n",
       "                                                                          'any...\n",
       "                                                              tokenizer=<function stemming_tokenizer at 0x000001C05C4E8310>)),\n",
       "                                             ('sel',\n",
       "                                              SelectKBest(k=100,\n",
       "                                                          score_func=<function chi2 at 0x000001C07B6451F0>)),\n",
       "                                             ('clf', MultinomialNB())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'tfidf__ngram_range': ((1, 1), (2, 2),\n",
       "                                                               (1, 2)),\n",
       "                                        'tfidf__norm': ('l1', 'l2'),\n",
       "                                        'tfidf__use_idf': (True, False)},\n",
       "                   random_state=333, refit='neg_log_loss',\n",
       "                   scoring=['neg_log_loss', 'accuracy', 'f1_macro',\n",
       "                            'roc_auc_ovr'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_NB_M.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_tfidf__norm</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>mean_test_roc_auc_ovr</th>\n",
       "      <th>rank_test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>832.669770</td>\n",
       "      <td>7.315610</td>\n",
       "      <td>-1.352277</td>\n",
       "      <td>0.018803</td>\n",
       "      <td>1</td>\n",
       "      <td>0.496983</td>\n",
       "      <td>1</td>\n",
       "      <td>0.279340</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820865</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>867.496801</td>\n",
       "      <td>5.077653</td>\n",
       "      <td>-1.360769</td>\n",
       "      <td>0.018256</td>\n",
       "      <td>2</td>\n",
       "      <td>0.486425</td>\n",
       "      <td>2</td>\n",
       "      <td>0.273254</td>\n",
       "      <td>2</td>\n",
       "      <td>0.823043</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>712.081686</td>\n",
       "      <td>95.545264</td>\n",
       "      <td>-1.440547</td>\n",
       "      <td>0.023772</td>\n",
       "      <td>3</td>\n",
       "      <td>0.460407</td>\n",
       "      <td>4</td>\n",
       "      <td>0.249352</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800748</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>861.374049</td>\n",
       "      <td>11.606753</td>\n",
       "      <td>-1.448230</td>\n",
       "      <td>0.024598</td>\n",
       "      <td>4</td>\n",
       "      <td>0.465686</td>\n",
       "      <td>3</td>\n",
       "      <td>0.249962</td>\n",
       "      <td>3</td>\n",
       "      <td>0.767584</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>875.210688</td>\n",
       "      <td>14.031734</td>\n",
       "      <td>-1.777598</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>5</td>\n",
       "      <td>0.305807</td>\n",
       "      <td>5</td>\n",
       "      <td>0.072405</td>\n",
       "      <td>5</td>\n",
       "      <td>0.768752</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_tfidf__ngram_range param_tfidf__use_idf param_tfidf__norm  \\\n",
       "5                   (1, 1)                 True                l2   \n",
       "8                   (1, 2)                 True                l2   \n",
       "9                   (2, 2)                 True                l2   \n",
       "3                   (2, 2)                False                l2   \n",
       "6                   (2, 2)                 True                l1   \n",
       "\n",
       "   mean_fit_time  std_fit_time  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "5     832.669770      7.315610               -1.352277               0.018803   \n",
       "8     867.496801      5.077653               -1.360769               0.018256   \n",
       "9     712.081686     95.545264               -1.440547               0.023772   \n",
       "3     861.374049     11.606753               -1.448230               0.024598   \n",
       "6     875.210688     14.031734               -1.777598               0.006466   \n",
       "\n",
       "   rank_test_neg_log_loss  mean_test_accuracy  rank_test_accuracy  \\\n",
       "5                       1            0.496983                   1   \n",
       "8                       2            0.486425                   2   \n",
       "9                       3            0.460407                   4   \n",
       "3                       4            0.465686                   3   \n",
       "6                       5            0.305807                   5   \n",
       "\n",
       "   mean_test_f1_macro  rank_test_f1_macro  mean_test_roc_auc_ovr  \\\n",
       "5            0.279340                   1               0.820865   \n",
       "8            0.273254                   2               0.823043   \n",
       "9            0.249352                   4               0.800748   \n",
       "3            0.249962                   3               0.767584   \n",
       "6            0.072405                   5               0.768752   \n",
       "\n",
       "   rank_test_roc_auc_ovr  \n",
       "5                      2  \n",
       "8                      1  \n",
       "9                      3  \n",
       "3                      6  \n",
       "6                      5  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_evaluate = [\"param_tfidf__ngram_range\",\"param_tfidf__use_idf\",\n",
    "                      \"param_tfidf__norm\"]\n",
    "NB_M_res = save_results(rs_NB_M,params_to_evaluate)\n",
    "NB_M_res.sort_values(by='mean_test_neg_log_loss',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados\n",
    "NB_M_res.to_csv('NB_M.csv')\n",
    "\n",
    "# Testing\n",
    "add_res(rs_NB_M,'NB_M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "clf2 = ComplementNB()\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1, 1),(2, 2),(1,2)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2')\n",
    " }\n",
    "pipeline2 = create_pipeline(clf2)\n",
    "rs_NB_C = create_rscv(pipeline2,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 219.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=333, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('tfidf',\n",
       "                                              TfidfVectorizer(max_features=1000,\n",
       "                                                              stop_words={'a',\n",
       "                                                                          'about',\n",
       "                                                                          'abov',\n",
       "                                                                          'above',\n",
       "                                                                          'after',\n",
       "                                                                          'afterward',\n",
       "                                                                          'again',\n",
       "                                                                          'against',\n",
       "                                                                          'al',\n",
       "                                                                          'al.',\n",
       "                                                                          'all',\n",
       "                                                                          'alon',\n",
       "                                                                          'alreadi',\n",
       "                                                                          'also',\n",
       "                                                                          'alway',\n",
       "                                                                          'am',\n",
       "                                                                          'an',\n",
       "                                                                          'analyz',\n",
       "                                                                          'analyze',\n",
       "                                                                          'and',\n",
       "                                                                          'ani',\n",
       "                                                                          'anoth',\n",
       "                                                                          'any',\n",
       "                                                                          'anyon',\n",
       "                                                                          'anyth',\n",
       "                                                                          'any...\n",
       "                                                              tokenizer=<function stemming_tokenizer at 0x000001C05C4E8310>)),\n",
       "                                             ('sel',\n",
       "                                              SelectKBest(k=100,\n",
       "                                                          score_func=<function chi2 at 0x000001C07B6451F0>)),\n",
       "                                             ('clf', ComplementNB())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'tfidf__ngram_range': ((1, 1), (2, 2),\n",
       "                                                               (1, 2)),\n",
       "                                        'tfidf__norm': ('l1', 'l2'),\n",
       "                                        'tfidf__use_idf': (True, False)},\n",
       "                   random_state=333, refit='neg_log_loss',\n",
       "                   scoring=['neg_log_loss', 'accuracy', 'f1_macro',\n",
       "                            'roc_auc_ovr'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_NB_C.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_tfidf__norm</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>mean_test_roc_auc_ovr</th>\n",
       "      <th>rank_test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>872.700056</td>\n",
       "      <td>5.901097</td>\n",
       "      <td>-1.929047</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.487934</td>\n",
       "      <td>5</td>\n",
       "      <td>0.346247</td>\n",
       "      <td>3</td>\n",
       "      <td>0.811420</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>838.188001</td>\n",
       "      <td>10.778160</td>\n",
       "      <td>-1.936767</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>2</td>\n",
       "      <td>0.496229</td>\n",
       "      <td>3</td>\n",
       "      <td>0.353996</td>\n",
       "      <td>1</td>\n",
       "      <td>0.817023</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>698.338261</td>\n",
       "      <td>110.145135</td>\n",
       "      <td>-1.952468</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>3</td>\n",
       "      <td>0.458899</td>\n",
       "      <td>9</td>\n",
       "      <td>0.317487</td>\n",
       "      <td>9</td>\n",
       "      <td>0.790708</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>866.117339</td>\n",
       "      <td>6.514185</td>\n",
       "      <td>-1.961592</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>4</td>\n",
       "      <td>0.476621</td>\n",
       "      <td>7</td>\n",
       "      <td>0.310295</td>\n",
       "      <td>10</td>\n",
       "      <td>0.798124</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>866.282724</td>\n",
       "      <td>4.560122</td>\n",
       "      <td>-2.163175</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>5</td>\n",
       "      <td>0.444947</td>\n",
       "      <td>10</td>\n",
       "      <td>0.325764</td>\n",
       "      <td>7</td>\n",
       "      <td>0.802587</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_tfidf__ngram_range param_tfidf__use_idf param_tfidf__norm  \\\n",
       "8                   (1, 2)                 True                l2   \n",
       "5                   (1, 1)                 True                l2   \n",
       "9                   (2, 2)                 True                l2   \n",
       "3                   (2, 2)                False                l2   \n",
       "6                   (2, 2)                 True                l1   \n",
       "\n",
       "   mean_fit_time  std_fit_time  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "8     872.700056      5.901097               -1.929047               0.002050   \n",
       "5     838.188001     10.778160               -1.936767               0.001177   \n",
       "9     698.338261    110.145135               -1.952468               0.002028   \n",
       "3     866.117339      6.514185               -1.961592               0.002667   \n",
       "6     866.282724      4.560122               -2.163175               0.001538   \n",
       "\n",
       "   rank_test_neg_log_loss  mean_test_accuracy  rank_test_accuracy  \\\n",
       "8                       1            0.487934                   5   \n",
       "5                       2            0.496229                   3   \n",
       "9                       3            0.458899                   9   \n",
       "3                       4            0.476621                   7   \n",
       "6                       5            0.444947                  10   \n",
       "\n",
       "   mean_test_f1_macro  rank_test_f1_macro  mean_test_roc_auc_ovr  \\\n",
       "8            0.346247                   3               0.811420   \n",
       "5            0.353996                   1               0.817023   \n",
       "9            0.317487                   9               0.790708   \n",
       "3            0.310295                  10               0.798124   \n",
       "6            0.325764                   7               0.802587   \n",
       "\n",
       "   rank_test_roc_auc_ovr  \n",
       "8                      4  \n",
       "5                      3  \n",
       "9                      7  \n",
       "3                      6  \n",
       "6                      5  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_evaluate = [\"param_tfidf__ngram_range\",\"param_tfidf__use_idf\",\n",
    "                      \"param_tfidf__norm\"]\n",
    "NB_C_res = save_results(rs_NB_C,params_to_evaluate)\n",
    "NB_C_res.sort_values(by='mean_test_neg_log_loss',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados\n",
    "NB_C_res.to_csv('NB_C.csv')\n",
    "\n",
    "# Testing\n",
    "add_res(rs_NB_C,'NB_C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1, 1),(2, 2),(1,2)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__n_neighbors': tuple(range(1,60,2))\n",
    " }\n",
    "pipeline5 = create_pipeline(knn)\n",
    "rs_KNN = create_rscv(pipeline5,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 217.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=333, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('tfidf',\n",
       "                                              TfidfVectorizer(max_features=1000,\n",
       "                                                              stop_words={'a',\n",
       "                                                                          'about',\n",
       "                                                                          'abov',\n",
       "                                                                          'above',\n",
       "                                                                          'after',\n",
       "                                                                          'afterward',\n",
       "                                                                          'again',\n",
       "                                                                          'against',\n",
       "                                                                          'al',\n",
       "                                                                          'al.',\n",
       "                                                                          'all',\n",
       "                                                                          'alon',\n",
       "                                                                          'alreadi',\n",
       "                                                                          'also',\n",
       "                                                                          'alway',\n",
       "                                                                          'am',\n",
       "                                                                          'an',\n",
       "                                                                          'analyz',\n",
       "                                                                          'analyze',\n",
       "                                                                          'and',\n",
       "                                                                          'ani',\n",
       "                                                                          'anoth',\n",
       "                                                                          'any',\n",
       "                                                                          'anyon',\n",
       "                                                                          'anyth',\n",
       "                                                                          'any...\n",
       "                                             ('clf', KNeighborsClassifier())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'clf__n_neighbors': (1, 3, 5, 7, 9, 11,\n",
       "                                                             13, 15, 17, 19, 21,\n",
       "                                                             23, 25, 27, 29, 31,\n",
       "                                                             33, 35, 37, 39, 41,\n",
       "                                                             43, 45, 47, 49, 51,\n",
       "                                                             53, 55, 57, 59),\n",
       "                                        'tfidf__ngram_range': ((1, 1), (2, 2),\n",
       "                                                               (1, 2)),\n",
       "                                        'tfidf__norm': ('l1', 'l2'),\n",
       "                                        'tfidf__use_idf': (True, False)},\n",
       "                   random_state=333, refit='neg_log_loss',\n",
       "                   scoring=['neg_log_loss', 'accuracy', 'f1_macro',\n",
       "                            'roc_auc_ovr'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_KNN.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_tfidf__norm</th>\n",
       "      <th>param_clf__n_neighbors</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>mean_test_roc_auc_ovr</th>\n",
       "      <th>rank_test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>57</td>\n",
       "      <td>677.003482</td>\n",
       "      <td>114.817929</td>\n",
       "      <td>-1.795803</td>\n",
       "      <td>0.088022</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497360</td>\n",
       "      <td>6</td>\n",
       "      <td>0.303354</td>\n",
       "      <td>7</td>\n",
       "      <td>0.806368</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>47</td>\n",
       "      <td>841.448306</td>\n",
       "      <td>11.810896</td>\n",
       "      <td>-1.837525</td>\n",
       "      <td>0.090814</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500754</td>\n",
       "      <td>5</td>\n",
       "      <td>0.304371</td>\n",
       "      <td>6</td>\n",
       "      <td>0.810575</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>53</td>\n",
       "      <td>855.881713</td>\n",
       "      <td>9.259894</td>\n",
       "      <td>-1.940506</td>\n",
       "      <td>0.047160</td>\n",
       "      <td>3</td>\n",
       "      <td>0.471719</td>\n",
       "      <td>10</td>\n",
       "      <td>0.249374</td>\n",
       "      <td>10</td>\n",
       "      <td>0.768794</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>43</td>\n",
       "      <td>858.314894</td>\n",
       "      <td>8.914673</td>\n",
       "      <td>-2.002848</td>\n",
       "      <td>0.167654</td>\n",
       "      <td>4</td>\n",
       "      <td>0.491704</td>\n",
       "      <td>8</td>\n",
       "      <td>0.295591</td>\n",
       "      <td>8</td>\n",
       "      <td>0.816810</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>39</td>\n",
       "      <td>844.940996</td>\n",
       "      <td>3.430423</td>\n",
       "      <td>-2.100618</td>\n",
       "      <td>0.063853</td>\n",
       "      <td>5</td>\n",
       "      <td>0.473228</td>\n",
       "      <td>9</td>\n",
       "      <td>0.262192</td>\n",
       "      <td>9</td>\n",
       "      <td>0.774652</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_tfidf__ngram_range param_tfidf__use_idf param_tfidf__norm  \\\n",
       "9                   (1, 1)                 True                l1   \n",
       "3                   (1, 1)                 True                l1   \n",
       "7                   (2, 2)                False                l1   \n",
       "2                   (1, 2)                 True                l2   \n",
       "1                   (2, 2)                False                l1   \n",
       "\n",
       "  param_clf__n_neighbors  mean_fit_time  std_fit_time  mean_test_neg_log_loss  \\\n",
       "9                     57     677.003482    114.817929               -1.795803   \n",
       "3                     47     841.448306     11.810896               -1.837525   \n",
       "7                     53     855.881713      9.259894               -1.940506   \n",
       "2                     43     858.314894      8.914673               -2.002848   \n",
       "1                     39     844.940996      3.430423               -2.100618   \n",
       "\n",
       "   std_test_neg_log_loss  rank_test_neg_log_loss  mean_test_accuracy  \\\n",
       "9               0.088022                       1            0.497360   \n",
       "3               0.090814                       2            0.500754   \n",
       "7               0.047160                       3            0.471719   \n",
       "2               0.167654                       4            0.491704   \n",
       "1               0.063853                       5            0.473228   \n",
       "\n",
       "   rank_test_accuracy  mean_test_f1_macro  rank_test_f1_macro  \\\n",
       "9                   6            0.303354                   7   \n",
       "3                   5            0.304371                   6   \n",
       "7                  10            0.249374                  10   \n",
       "2                   8            0.295591                   8   \n",
       "1                   9            0.262192                   9   \n",
       "\n",
       "   mean_test_roc_auc_ovr  rank_test_roc_auc_ovr  \n",
       "9               0.806368                      5  \n",
       "3               0.810575                      4  \n",
       "7               0.768794                      9  \n",
       "2               0.816810                      3  \n",
       "1               0.774652                      8  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_evaluate = [\"param_tfidf__ngram_range\",\"param_tfidf__use_idf\",\n",
    "                      \"param_tfidf__norm\",\"param_clf__n_neighbors\"]\n",
    "KNN_res = save_results(rs_KNN,params_to_evaluate)\n",
    "KNN_res.sort_values(by='mean_test_neg_log_loss',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados\n",
    "KNN_res.to_csv('KNN.csv')\n",
    "\n",
    "# Testing\n",
    "add_res(rs_KNN,'KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf3 = RandomForestClassifier(random_state=SEED)\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1, 1),(2, 2),(1,2)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__criterion':('giny','entropy')\n",
    " }\n",
    "pipeline3 = create_pipeline(clf3)\n",
    "rs_RF = create_rscv(pipeline3,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 152.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=333, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('tfidf',\n",
       "                                              TfidfVectorizer(max_features=1000,\n",
       "                                                              stop_words={'a',\n",
       "                                                                          'about',\n",
       "                                                                          'abov',\n",
       "                                                                          'above',\n",
       "                                                                          'after',\n",
       "                                                                          'afterward',\n",
       "                                                                          'again',\n",
       "                                                                          'against',\n",
       "                                                                          'al',\n",
       "                                                                          'al.',\n",
       "                                                                          'all',\n",
       "                                                                          'alon',\n",
       "                                                                          'alreadi',\n",
       "                                                                          'also',\n",
       "                                                                          'alway',\n",
       "                                                                          'am',\n",
       "                                                                          'an',\n",
       "                                                                          'analyz',\n",
       "                                                                          'analyze',\n",
       "                                                                          'and',\n",
       "                                                                          'ani',\n",
       "                                                                          'anoth',\n",
       "                                                                          'any',\n",
       "                                                                          'anyon',\n",
       "                                                                          'anyth',\n",
       "                                                                          'any...\n",
       "                                                          score_func=<function chi2 at 0x000001C07B6451F0>)),\n",
       "                                             ('clf',\n",
       "                                              RandomForestClassifier(random_state=333))]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'clf__criterion': ('giny', 'entropy'),\n",
       "                                        'tfidf__ngram_range': ((1, 1), (2, 2),\n",
       "                                                               (1, 2)),\n",
       "                                        'tfidf__norm': ('l1', 'l2'),\n",
       "                                        'tfidf__use_idf': (True, False)},\n",
       "                   random_state=333, refit='neg_log_loss',\n",
       "                   scoring=['neg_log_loss', 'accuracy', 'f1_macro',\n",
       "                            'roc_auc_ovr'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_RF.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_tfidf__norm</th>\n",
       "      <th>param_clf__criterion</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>mean_test_roc_auc_ovr</th>\n",
       "      <th>rank_test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>846.342358</td>\n",
       "      <td>6.367995</td>\n",
       "      <td>-1.716357</td>\n",
       "      <td>0.109455</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636878</td>\n",
       "      <td>1</td>\n",
       "      <td>0.509188</td>\n",
       "      <td>2</td>\n",
       "      <td>0.860015</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>875.439546</td>\n",
       "      <td>7.584559</td>\n",
       "      <td>-1.733858</td>\n",
       "      <td>0.079476</td>\n",
       "      <td>2</td>\n",
       "      <td>0.630468</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500353</td>\n",
       "      <td>3</td>\n",
       "      <td>0.871041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>864.009314</td>\n",
       "      <td>6.412850</td>\n",
       "      <td>-1.791540</td>\n",
       "      <td>0.091041</td>\n",
       "      <td>3</td>\n",
       "      <td>0.632353</td>\n",
       "      <td>2</td>\n",
       "      <td>0.509479</td>\n",
       "      <td>1</td>\n",
       "      <td>0.868033</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>871.857783</td>\n",
       "      <td>6.314054</td>\n",
       "      <td>-1.994690</td>\n",
       "      <td>0.064708</td>\n",
       "      <td>4</td>\n",
       "      <td>0.625566</td>\n",
       "      <td>4</td>\n",
       "      <td>0.497413</td>\n",
       "      <td>4</td>\n",
       "      <td>0.861950</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>giny</td>\n",
       "      <td>825.540492</td>\n",
       "      <td>6.719300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_tfidf__ngram_range param_tfidf__use_idf param_tfidf__norm  \\\n",
       "8                   (1, 1)                False                l2   \n",
       "3                   (1, 2)                False                l1   \n",
       "0                   (1, 2)                 True                l1   \n",
       "5                   (2, 2)                False                l1   \n",
       "1                   (1, 1)                False                l1   \n",
       "\n",
       "  param_clf__criterion  mean_fit_time  std_fit_time  mean_test_neg_log_loss  \\\n",
       "8              entropy     846.342358      6.367995               -1.716357   \n",
       "3              entropy     875.439546      7.584559               -1.733858   \n",
       "0              entropy     864.009314      6.412850               -1.791540   \n",
       "5              entropy     871.857783      6.314054               -1.994690   \n",
       "1                 giny     825.540492      6.719300                     NaN   \n",
       "\n",
       "   std_test_neg_log_loss  rank_test_neg_log_loss  mean_test_accuracy  \\\n",
       "8               0.109455                       1            0.636878   \n",
       "3               0.079476                       2            0.630468   \n",
       "0               0.091041                       3            0.632353   \n",
       "5               0.064708                       4            0.625566   \n",
       "1                    NaN                       5                 NaN   \n",
       "\n",
       "   rank_test_accuracy  mean_test_f1_macro  rank_test_f1_macro  \\\n",
       "8                   1            0.509188                   2   \n",
       "3                   3            0.500353                   3   \n",
       "0                   2            0.509479                   1   \n",
       "5                   4            0.497413                   4   \n",
       "1                   5                 NaN                   5   \n",
       "\n",
       "   mean_test_roc_auc_ovr  rank_test_roc_auc_ovr  \n",
       "8               0.860015                      4  \n",
       "3               0.871041                      1  \n",
       "0               0.868033                      2  \n",
       "5               0.861950                      3  \n",
       "1                    NaN                      5  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_evaluate = [\"param_tfidf__ngram_range\",\"param_tfidf__use_idf\",\n",
    "                      \"param_tfidf__norm\",\"param_clf__criterion\"]\n",
    "RF_res = save_results(rs_RF,params_to_evaluate)\n",
    "RF_res.sort_values(by='mean_test_neg_log_loss',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados\n",
    "RF_res.to_csv('RF.csv')\n",
    "\n",
    "# Testing\n",
    "add_res(rs_RF,'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf4 = SVC(probability=True)\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1, 1),(2, 2),(1,2)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__kernel':('linear','rbf','sigmoid','poly')\n",
    " }\n",
    "pipeline4 = create_pipeline(clf4)\n",
    "rs_SVC = create_rscv(pipeline4,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 218.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=333, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('tfidf',\n",
       "                                              TfidfVectorizer(max_features=1000,\n",
       "                                                              stop_words={'a',\n",
       "                                                                          'about',\n",
       "                                                                          'abov',\n",
       "                                                                          'above',\n",
       "                                                                          'after',\n",
       "                                                                          'afterward',\n",
       "                                                                          'again',\n",
       "                                                                          'against',\n",
       "                                                                          'al',\n",
       "                                                                          'al.',\n",
       "                                                                          'all',\n",
       "                                                                          'alon',\n",
       "                                                                          'alreadi',\n",
       "                                                                          'also',\n",
       "                                                                          'alway',\n",
       "                                                                          'am',\n",
       "                                                                          'an',\n",
       "                                                                          'analyz',\n",
       "                                                                          'analyze',\n",
       "                                                                          'and',\n",
       "                                                                          'ani',\n",
       "                                                                          'anoth',\n",
       "                                                                          'any',\n",
       "                                                                          'anyon',\n",
       "                                                                          'anyth',\n",
       "                                                                          'any...\n",
       "                                                          score_func=<function chi2 at 0x000001C07B6451F0>)),\n",
       "                                             ('clf', SVC(probability=True))]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'clf__kernel': ('linear', 'rbf',\n",
       "                                                        'sigmoid', 'poly'),\n",
       "                                        'tfidf__ngram_range': ((1, 1), (2, 2),\n",
       "                                                               (1, 2)),\n",
       "                                        'tfidf__norm': ('l1', 'l2'),\n",
       "                                        'tfidf__use_idf': (True, False)},\n",
       "                   random_state=333, refit='neg_log_loss',\n",
       "                   scoring=['neg_log_loss', 'accuracy', 'f1_macro',\n",
       "                            'roc_auc_ovr'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_SVC.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "      <th>param_tfidf__norm</th>\n",
       "      <th>param_clf__kernel</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>mean_test_roc_auc_ovr</th>\n",
       "      <th>rank_test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>l2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>845.883572</td>\n",
       "      <td>3.057758</td>\n",
       "      <td>-1.198334</td>\n",
       "      <td>0.019055</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556184</td>\n",
       "      <td>2</td>\n",
       "      <td>0.413020</td>\n",
       "      <td>2</td>\n",
       "      <td>0.844356</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>l2</td>\n",
       "      <td>poly</td>\n",
       "      <td>876.303451</td>\n",
       "      <td>7.451146</td>\n",
       "      <td>-1.199707</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>2</td>\n",
       "      <td>0.571644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450205</td>\n",
       "      <td>1</td>\n",
       "      <td>0.849967</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>l2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>869.909851</td>\n",
       "      <td>10.996822</td>\n",
       "      <td>-1.209642</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>3</td>\n",
       "      <td>0.554676</td>\n",
       "      <td>3</td>\n",
       "      <td>0.408786</td>\n",
       "      <td>3</td>\n",
       "      <td>0.841868</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>l2</td>\n",
       "      <td>linear</td>\n",
       "      <td>871.635556</td>\n",
       "      <td>5.475896</td>\n",
       "      <td>-1.232457</td>\n",
       "      <td>0.037320</td>\n",
       "      <td>4</td>\n",
       "      <td>0.532051</td>\n",
       "      <td>4</td>\n",
       "      <td>0.328426</td>\n",
       "      <td>5</td>\n",
       "      <td>0.836723</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>l2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>861.795021</td>\n",
       "      <td>2.723015</td>\n",
       "      <td>-1.312631</td>\n",
       "      <td>0.010962</td>\n",
       "      <td>5</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.357043</td>\n",
       "      <td>4</td>\n",
       "      <td>0.792663</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_tfidf__use_idf param_tfidf__ngram_range param_tfidf__norm  \\\n",
       "7                 True                   (1, 1)                l2   \n",
       "8                False                   (1, 2)                l2   \n",
       "5                 True                   (1, 2)                l2   \n",
       "4                False                   (1, 2)                l2   \n",
       "0                 True                   (2, 2)                l2   \n",
       "\n",
       "  param_clf__kernel  mean_fit_time  std_fit_time  mean_test_neg_log_loss  \\\n",
       "7               rbf     845.883572      3.057758               -1.198334   \n",
       "8              poly     876.303451      7.451146               -1.199707   \n",
       "5               rbf     869.909851     10.996822               -1.209642   \n",
       "4            linear     871.635556      5.475896               -1.232457   \n",
       "0               rbf     861.795021      2.723015               -1.312631   \n",
       "\n",
       "   std_test_neg_log_loss  rank_test_neg_log_loss  mean_test_accuracy  \\\n",
       "7               0.019055                       1            0.556184   \n",
       "8               0.016758                       2            0.571644   \n",
       "5               0.011874                       3            0.554676   \n",
       "4               0.037320                       4            0.532051   \n",
       "0               0.010962                       5            0.518100   \n",
       "\n",
       "   rank_test_accuracy  mean_test_f1_macro  rank_test_f1_macro  \\\n",
       "7                   2            0.413020                   2   \n",
       "8                   1            0.450205                   1   \n",
       "5                   3            0.408786                   3   \n",
       "4                   4            0.328426                   5   \n",
       "0                   5            0.357043                   4   \n",
       "\n",
       "   mean_test_roc_auc_ovr  rank_test_roc_auc_ovr  \n",
       "7               0.844356                      2  \n",
       "8               0.849967                      1  \n",
       "5               0.841868                      3  \n",
       "4               0.836723                      4  \n",
       "0               0.792663                      8  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_evaluate = [\"param_tfidf__use_idf\",\"param_tfidf__ngram_range\",\"param_tfidf__norm\",\"param_clf__kernel\"]\n",
    "SVC_res = save_results(rs_SVC,params_to_evaluate)\n",
    "SVC_res.sort_values(by='mean_test_neg_log_loss',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados\n",
    "SVC_res.to_csv('SVC.csv')\n",
    "\n",
    "# Testing\n",
    "add_res(rs_SVC,'SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB_M</td>\n",
       "      <td>1.330832</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.262989</td>\n",
       "      <td>0.827320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB_C</td>\n",
       "      <td>1.916608</td>\n",
       "      <td>0.495482</td>\n",
       "      <td>0.338819</td>\n",
       "      <td>0.802271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>1.829654</td>\n",
       "      <td>0.490964</td>\n",
       "      <td>0.291027</td>\n",
       "      <td>0.817899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>1.622715</td>\n",
       "      <td>0.623494</td>\n",
       "      <td>0.525726</td>\n",
       "      <td>0.848051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1.172317</td>\n",
       "      <td>0.560241</td>\n",
       "      <td>0.421162</td>\n",
       "      <td>0.845402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clf  log_loss  accuracy  f1-macro       ROC\n",
       "0  NB_M  1.330832  0.500000  0.262989  0.827320\n",
       "1  NB_C  1.916608  0.495482  0.338819  0.802271\n",
       "2   KNN  1.829654  0.490964  0.291027  0.817899\n",
       "3    RF  1.622715  0.623494  0.525726  0.848051\n",
       "4   SVC  1.172317  0.560241  0.421162  0.845402"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exportamos resultados totales\n",
    "df_results.to_csv('df_rs.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
