{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constantes y Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Semilla\n",
    "SEED = 333\n",
    "\n",
    "# Preparamos el lematizado\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Lematizar un string\n",
    "import re\n",
    "def stemming_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "## Columnas de guardado para los algortimos \n",
    "COLUMNS = ['mean_fit_time','std_fit_time','mean_test_neg_log_loss','std_test_neg_log_loss','rank_test_neg_log_loss',\n",
    "           'mean_test_accuracy','rank_test_accuracy',\n",
    "           'mean_test_f1_macro','rank_test_f1_macro',\n",
    "           'mean_test_roc_auc_ovr','rank_test_roc_auc_ovr']\n",
    "\n",
    "# Funcion de guardado de resultados que es un subconjunto de cv_results. \n",
    "# Guarda los resultados de los parametros del algoritmo y las metricas que le pasamos como parametro.\n",
    "def save_results(rs,params_to_evaluate,columns=COLUMNS):\n",
    "    aux = pd.DataFrame(rs.cv_results_)\n",
    "    gs_res = pd.DataFrame()\n",
    "    for col in params_to_evaluate:\n",
    "        gs_res[col] = aux[col]\n",
    "    for col in columns:\n",
    "        gs_res[col] = aux[col]\n",
    "    return gs_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "      <td>Recent evidence has demonstrated that acquired...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gene             Variation  Class  \\\n",
       "ID                                        \n",
       "0   FAM58A  Truncating Mutations      1   \n",
       "1      CBL                 W802*      2   \n",
       "2      CBL                 Q249E      2   \n",
       "3      CBL                 N454D      3   \n",
       "4      CBL                 L399V      4   \n",
       "\n",
       "                                                 Text  \n",
       "ID                                                     \n",
       "0   Cyclin-dependent kinases (CDKs) regulate a var...  \n",
       "1    Abstract Background  Non-small cell lung canc...  \n",
       "2    Abstract Background  Non-small cell lung canc...  \n",
       "3   Recent evidence has demonstrated that acquired...  \n",
       "4   Oncogenic mutations in the monomeric Casitas B...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Carga de los archivos \n",
    "train_variants_df = pd.read_csv(r\"C:\\Users\\Junio\\Libretas\\data-c\\training_variants\", index_col='ID',engine='python')\n",
    "train_txt_df = pd.read_csv(r\"C:\\Users\\Junio\\Libretas\\data-c/training_text\", sep=\"\\|\\|\", index_col='ID',engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "\n",
    "# Union de ambos archivos en un dataframe\n",
    "df_all = pd.merge(train_variants_df, train_txt_df, how='left', on='ID')\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparacion del Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>RASA1</td>\n",
       "      <td>1</td>\n",
       "      <td>Inactivation of Ras GTPase activating proteins...</td>\n",
       "      <td>3343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>MYD88</td>\n",
       "      <td>7</td>\n",
       "      <td>MYD88 L265P is a somatic mutation that has bee...</td>\n",
       "      <td>3005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>RARA</td>\n",
       "      <td>6</td>\n",
       "      <td>We describe the case of a patient presenting w...</td>\n",
       "      <td>11198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>MSH6</td>\n",
       "      <td>4</td>\n",
       "      <td>Endometrial cancer is the most common gynecolo...</td>\n",
       "      <td>19533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>KRAS</td>\n",
       "      <td>7</td>\n",
       "      <td>Transforming mutations in NRAS and KRAS are th...</td>\n",
       "      <td>15135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>FANCA</td>\n",
       "      <td>1</td>\n",
       "      <td>Abstract Fanconi anemia is characterized by c...</td>\n",
       "      <td>14851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>2</td>\n",
       "      <td>Many studies have reported the EGFR mutations ...</td>\n",
       "      <td>3837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>YAP1</td>\n",
       "      <td>7</td>\n",
       "      <td>The development of array comparative genomic h...</td>\n",
       "      <td>65740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>BRAF</td>\n",
       "      <td>7</td>\n",
       "      <td>Over 30 mutations of the B-RAF gene associated...</td>\n",
       "      <td>6895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>TSC2</td>\n",
       "      <td>1</td>\n",
       "      <td>Tuberous sclerosis (TSC) is an autosomal domin...</td>\n",
       "      <td>10154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gene  Class                                               Text  \\\n",
       "ID                                                                      \n",
       "3198  RASA1      1  Inactivation of Ras GTPase activating proteins...   \n",
       "2084  MYD88      7  MYD88 L265P is a somatic mutation that has bee...   \n",
       "3185   RARA      6  We describe the case of a patient presenting w...   \n",
       "113    MSH6      4  Endometrial cancer is the most common gynecolo...   \n",
       "3133   KRAS      7  Transforming mutations in NRAS and KRAS are th...   \n",
       "1110  FANCA      1   Abstract Fanconi anemia is characterized by c...   \n",
       "153    EGFR      2  Many studies have reported the EGFR mutations ...   \n",
       "1242   YAP1      7  The development of array comparative genomic h...   \n",
       "2768   BRAF      7  Over 30 mutations of the B-RAF gene associated...   \n",
       "1045   TSC2      1  Tuberous sclerosis (TSC) is an autosomal domin...   \n",
       "\n",
       "      Text_count  \n",
       "ID                \n",
       "3198        3343  \n",
       "2084        3005  \n",
       "3185       11198  \n",
       "113        19533  \n",
       "3133       15135  \n",
       "1110       14851  \n",
       "153         3837  \n",
       "1242       65740  \n",
       "2768        6895  \n",
       "1045       10154  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminamos Variation pues no aporta mucha informacion (hay casi un valor para cada caso)\n",
    "df = df_all.drop([\"Variation\"], axis=1)\n",
    "\n",
    "# Añadimos una columna que nos indica el tamaño del texto de cada instancia\n",
    "df['Text_count']  = df_all[\"Text\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Nos quedamos con las instancias que no tengan el texto nulo\n",
    "df = df[df['Text_count']!=1]\n",
    "\n",
    "# Mostramos el dataframe\n",
    "df.sample(10,random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparando la Clasificacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separacion training/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop([\"Class\",\"Text_count\"], axis=1)\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando stop_words\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "# Capturando las palabras que no se encuentran en STOPWORDS por ser una contraccion de la palabra original (salida de stemming_tokenizer)\n",
    "contract_words = {'abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', \n",
    "              'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', \n",
    "              'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', \n",
    "              'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', \n",
    "              'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', \n",
    "              'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', \n",
    "              'someth', 'sometim', 'somewher', 'themselv', 'thenc', \n",
    "              'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', \n",
    "              'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', \n",
    "              'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'}\n",
    "\n",
    "l2 = {'anywh', 'aren', 'becau', 'couldn', 'd', 'didn', 'doe', \n",
    "      'doesn', 'don', 'el', 'elsewh', 'everywh', 'hadn', 'hasn', \n",
    "      'haven', 'ind', 'isn', 'let', 'll', 'm', 'mustn', \n",
    "      'otherwi', 'plea', 're', 's', 'shan', 'shouldn', \n",
    "      'somewh', 't', 've', 'wasn', 'weren', 'won', 'wouldn'}\n",
    "\n",
    "custom_words = {\"fig\", \"figure\", \"et\", \"al\", \"al.\", \"also\",\n",
    "                \"data\", \"analyze\", \"study\", \"table\", \"using\",\n",
    "                \"method\", \"result\", \"conclusion\", \"author\", \n",
    "                \"find\", \"found\", \"show\", \"casita\",\"non\",\"name\",\"image\",\n",
    "                'analyz', 'conclus', 'figur','conclu', 'imag', 'studi', 'tabl', 'use'}\n",
    "# Unimos ambas listas\n",
    "stop_words = STOPWORDS.union(contract_words).union(l2).union(custom_words)\n",
    "\n",
    "# Creacion del pipeline \n",
    "from imblearn.pipeline import make_pipeline as make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def create_pipeline(estimator,ngram_range=(1,1)):\n",
    "    # Segun la columna, elegimos un preprocesado u otro\n",
    "    preprocess = ColumnTransformer(\n",
    "          # Binarizado para Gene\n",
    "        [('binarizado_gene', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['Gene']),\n",
    "         ('tfidf_evidence', TfidfVectorizer(analyzer=\"word\", \n",
    "                            tokenizer=stemming_tokenizer,stop_words= stop_words,ngram_range=ngram_range), 'Text')],\n",
    "        remainder='passthrough')\n",
    "\n",
    "    return make_pipeline(preprocess,estimator)\n",
    "\n",
    "# Validacion Cruzada Stratificada(n_splits=3):\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "CV = StratifiedKFold(n_splits=3, random_state=SEED, shuffle=True)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "def create_rscv(pipeline,params,n_iterations = 10,scoring = [\"neg_log_loss\",\"accuracy\",\"f1_macro\",\"roc_auc_ovr\"],cv = CV):\n",
    "    return RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            params,\n",
    "            n_iter = n_iterations,\n",
    "            verbose = 1,\n",
    "            random_state = SEED,\n",
    "            cv = cv,\n",
    "            n_jobs = -1,\n",
    "            scoring = scoring,\n",
    "            refit = \"neg_log_loss\" \n",
    "            )\n",
    "# Importamos la metrica principal de evaluacion\n",
    "from sklearn import metrics\n",
    "\n",
    "# Dataframe de guardado del test\n",
    "df_results = pd.DataFrame(columns = [\"clf\",\"log_loss\",\"accuracy\",\"f1-macro\",\"ROC\"])\n",
    "\n",
    "# Funcion de guardado del resultado del test\n",
    "def add_res(clf,name,X_test = X_test):   \n",
    "    # Guardamos las predicciones\n",
    "    y_predict_proba = clf.predict_proba(X_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Guardamos los resultados de las distintas metricas\n",
    "    log_loss = metrics.log_loss(y_test,y_predict_proba)\n",
    "    acc = metrics.accuracy_score(y_test,y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "    roc = metrics.roc_auc_score(y_test,y_predict_proba,multi_class='ovr')\n",
    "    \n",
    "    # Actualizamos el dataframe\n",
    "    df_results.loc[len(df_results)]=[name,log_loss,acc,f1,roc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://towardsdatascience.com/pipeline-columntransformer-and-featureunion-explained-f5491f815f\n",
    "* https://towardsdatascience.com/columntransformer-meets-natural-language-processing-da1f116dd69f\n",
    "* https://towardsdatascience.com/columntransformer-meets-natural-language-processing-da1f116dd69f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf2 = MultinomialNB()\n",
    "parameters = {\n",
    "    'columntransformer__tfidf_evidence__ngram_range': ((1, 1),(2, 2),(1,2)),\n",
    "    'columntransformer__tfidf_evidence__use_idf': (True, False),\n",
    "    'columntransformer__tfidf_evidence__max_features': (1000,2000,3000,4000,5000,6000,7000,8000,9000,None),\n",
    "    'columntransformer__tfidf_evidence__norm': ('l1', 'l2')\n",
    " }\n",
    "pipeline = create_pipeline(clf2)\n",
    "rs_NB_M = create_rscv(pipeline,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 216.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=333, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(remainder='passthrough',\n",
       "                                                                transformers=[('binarizado_gene',\n",
       "                                                                               OneHotEncoder(dtype='int',\n",
       "                                                                                             handle_unknown='ignore'),\n",
       "                                                                               ['Gene']),\n",
       "                                                                              ('tfidf_evidence',\n",
       "                                                                               TfidfVectorizer(stop_words={'a',\n",
       "                                                                                                           'about',\n",
       "                                                                                                           'abov',\n",
       "                                                                                                           'above',\n",
       "                                                                                                           'after',\n",
       "                                                                                                           'after...\n",
       "                   param_distributions={'columntransformer__tfidf_evidence__max_features': (1000,\n",
       "                                                                                            2000,\n",
       "                                                                                            3000,\n",
       "                                                                                            4000,\n",
       "                                                                                            5000,\n",
       "                                                                                            6000,\n",
       "                                                                                            7000,\n",
       "                                                                                            8000,\n",
       "                                                                                            9000,\n",
       "                                                                                            None),\n",
       "                                        'columntransformer__tfidf_evidence__ngram_range': ((1,\n",
       "                                                                                            1),\n",
       "                                                                                           (2,\n",
       "                                                                                            2),\n",
       "                                                                                           (1,\n",
       "                                                                                            2)),\n",
       "                                        'columntransformer__tfidf_evidence__norm': ('l1',\n",
       "                                                                                    'l2'),\n",
       "                                        'columntransformer__tfidf_evidence__use_idf': (True,\n",
       "                                                                                       False)},\n",
       "                   random_state=333, refit='neg_log_loss',\n",
       "                   scoring=['neg_log_loss', 'accuracy', 'f1_macro',\n",
       "                            'roc_auc_ovr'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_NB_M.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_columntransformer__tfidf_evidence__max_features</th>\n",
       "      <th>param_columntransformer__tfidf_evidence__ngram_range</th>\n",
       "      <th>param_columntransformer__tfidf_evidence__use_idf</th>\n",
       "      <th>param_columntransformer__tfidf_evidence__norm</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>mean_test_roc_auc_ovr</th>\n",
       "      <th>rank_test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>855.009356</td>\n",
       "      <td>4.248354</td>\n",
       "      <td>-1.271191</td>\n",
       "      <td>0.018626</td>\n",
       "      <td>1</td>\n",
       "      <td>0.548643</td>\n",
       "      <td>3</td>\n",
       "      <td>0.287230</td>\n",
       "      <td>3</td>\n",
       "      <td>0.840346</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>692.936533</td>\n",
       "      <td>118.172069</td>\n",
       "      <td>-1.283196</td>\n",
       "      <td>0.018733</td>\n",
       "      <td>2</td>\n",
       "      <td>0.546380</td>\n",
       "      <td>4</td>\n",
       "      <td>0.276995</td>\n",
       "      <td>4</td>\n",
       "      <td>0.838525</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>826.079748</td>\n",
       "      <td>7.797303</td>\n",
       "      <td>-1.289574</td>\n",
       "      <td>0.019074</td>\n",
       "      <td>3</td>\n",
       "      <td>0.543363</td>\n",
       "      <td>6</td>\n",
       "      <td>0.274864</td>\n",
       "      <td>5</td>\n",
       "      <td>0.836459</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>876.746928</td>\n",
       "      <td>15.788748</td>\n",
       "      <td>-1.290690</td>\n",
       "      <td>0.018820</td>\n",
       "      <td>4</td>\n",
       "      <td>0.543741</td>\n",
       "      <td>5</td>\n",
       "      <td>0.274754</td>\n",
       "      <td>6</td>\n",
       "      <td>0.836819</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>862.549008</td>\n",
       "      <td>9.225927</td>\n",
       "      <td>-1.291660</td>\n",
       "      <td>0.018897</td>\n",
       "      <td>5</td>\n",
       "      <td>0.541855</td>\n",
       "      <td>7</td>\n",
       "      <td>0.273358</td>\n",
       "      <td>7</td>\n",
       "      <td>0.836763</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_columntransformer__tfidf_evidence__max_features  \\\n",
       "0                                               3000      \n",
       "9                                               6000      \n",
       "4                                               5000      \n",
       "5                                               6000      \n",
       "3                                               3000      \n",
       "\n",
       "  param_columntransformer__tfidf_evidence__ngram_range  \\\n",
       "0                                             (2, 2)     \n",
       "9                                             (2, 2)     \n",
       "4                                             (1, 1)     \n",
       "5                                             (1, 2)     \n",
       "3                                             (1, 2)     \n",
       "\n",
       "  param_columntransformer__tfidf_evidence__use_idf  \\\n",
       "0                                             True   \n",
       "9                                             True   \n",
       "4                                             True   \n",
       "5                                             True   \n",
       "3                                            False   \n",
       "\n",
       "  param_columntransformer__tfidf_evidence__norm  mean_fit_time  std_fit_time  \\\n",
       "0                                            l1     855.009356      4.248354   \n",
       "9                                            l1     692.936533    118.172069   \n",
       "4                                            l1     826.079748      7.797303   \n",
       "5                                            l1     876.746928     15.788748   \n",
       "3                                            l1     862.549008      9.225927   \n",
       "\n",
       "   mean_test_neg_log_loss  std_test_neg_log_loss  rank_test_neg_log_loss  \\\n",
       "0               -1.271191               0.018626                       1   \n",
       "9               -1.283196               0.018733                       2   \n",
       "4               -1.289574               0.019074                       3   \n",
       "5               -1.290690               0.018820                       4   \n",
       "3               -1.291660               0.018897                       5   \n",
       "\n",
       "   mean_test_accuracy  rank_test_accuracy  mean_test_f1_macro  \\\n",
       "0            0.548643                   3            0.287230   \n",
       "9            0.546380                   4            0.276995   \n",
       "4            0.543363                   6            0.274864   \n",
       "5            0.543741                   5            0.274754   \n",
       "3            0.541855                   7            0.273358   \n",
       "\n",
       "   rank_test_f1_macro  mean_test_roc_auc_ovr  rank_test_roc_auc_ovr  \n",
       "0                   3               0.840346                      2  \n",
       "9                   4               0.838525                      3  \n",
       "4                   5               0.836459                      6  \n",
       "5                   6               0.836819                      4  \n",
       "3                   7               0.836763                      5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_evaluate = [\"param_columntransformer__tfidf_evidence__max_features\",\n",
    "                      \"param_columntransformer__tfidf_evidence__ngram_range\",\n",
    "                      \"param_columntransformer__tfidf_evidence__use_idf\",\n",
    "                      \"param_columntransformer__tfidf_evidence__norm\"]\n",
    "NB_M_res = save_results(rs_NB_M,params_to_evaluate)\n",
    "NB_M_res.sort_values(by='mean_test_neg_log_loss',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados\n",
    "NB_M_res.to_csv('NB_M.csv')\n",
    "\n",
    "# Testing\n",
    "add_res(rs_NB_M,'NB_M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf3 = RandomForestClassifier(random_state=SEED)\n",
    "parameters = {\n",
    "    'columntransformer__tfidf_evidence__ngram_range': ((1, 1),(2, 2),(1,2)),\n",
    "    'columntransformer__tfidf_evidence__use_idf': (True, False),\n",
    "    'columntransformer__tfidf_evidence__max_features': (1000,2000,3000,4000,5000,6000,7000,8000,9000,None),\n",
    "    'columntransformer__tfidf_evidence__norm': ('l1', 'l2'),\n",
    "    'randomforestclassifier__criterion':('giny','entropy')\n",
    " }\n",
    "pipeline3 = create_pipeline(clf3)\n",
    "rs_RF = create_rscv(pipeline3,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 156.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=333, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(remainder='passthrough',\n",
       "                                                                transformers=[('binarizado_gene',\n",
       "                                                                               OneHotEncoder(dtype='int',\n",
       "                                                                                             handle_unknown='ignore'),\n",
       "                                                                               ['Gene']),\n",
       "                                                                              ('tfidf_evidence',\n",
       "                                                                               TfidfVectorizer(stop_words={'a',\n",
       "                                                                                                           'about',\n",
       "                                                                                                           'abov',\n",
       "                                                                                                           'above',\n",
       "                                                                                                           'after',\n",
       "                                                                                                           'after...\n",
       "                                                                                            None),\n",
       "                                        'columntransformer__tfidf_evidence__ngram_range': ((1,\n",
       "                                                                                            1),\n",
       "                                                                                           (2,\n",
       "                                                                                            2),\n",
       "                                                                                           (1,\n",
       "                                                                                            2)),\n",
       "                                        'columntransformer__tfidf_evidence__norm': ('l1',\n",
       "                                                                                    'l2'),\n",
       "                                        'columntransformer__tfidf_evidence__use_idf': (True,\n",
       "                                                                                       False),\n",
       "                                        'randomforestclassifier__criterion': ('giny',\n",
       "                                                                              'entropy')},\n",
       "                   random_state=333, refit='neg_log_loss',\n",
       "                   scoring=['neg_log_loss', 'accuracy', 'f1_macro',\n",
       "                            'roc_auc_ovr'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_RF.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_columntransformer__tfidf_evidence__max_features</th>\n",
       "      <th>param_columntransformer__tfidf_evidence__ngram_range</th>\n",
       "      <th>param_columntransformer__tfidf_evidence__use_idf</th>\n",
       "      <th>param_columntransformer__tfidf_evidence__norm</th>\n",
       "      <th>param_randomforestclassifier__criterion</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>mean_test_roc_auc_ovr</th>\n",
       "      <th>rank_test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>871.215560</td>\n",
       "      <td>8.144630</td>\n",
       "      <td>-1.688463</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>1</td>\n",
       "      <td>0.643665</td>\n",
       "      <td>1</td>\n",
       "      <td>0.505800</td>\n",
       "      <td>3</td>\n",
       "      <td>0.860355</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>916.800501</td>\n",
       "      <td>5.654871</td>\n",
       "      <td>-1.723829</td>\n",
       "      <td>0.192871</td>\n",
       "      <td>2</td>\n",
       "      <td>0.637632</td>\n",
       "      <td>3</td>\n",
       "      <td>0.506809</td>\n",
       "      <td>2</td>\n",
       "      <td>0.876764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1152.113806</td>\n",
       "      <td>17.604980</td>\n",
       "      <td>-1.769758</td>\n",
       "      <td>0.136692</td>\n",
       "      <td>3</td>\n",
       "      <td>0.633107</td>\n",
       "      <td>4</td>\n",
       "      <td>0.493645</td>\n",
       "      <td>4</td>\n",
       "      <td>0.859302</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>897.049993</td>\n",
       "      <td>6.941904</td>\n",
       "      <td>-1.784257</td>\n",
       "      <td>0.101149</td>\n",
       "      <td>4</td>\n",
       "      <td>0.642911</td>\n",
       "      <td>2</td>\n",
       "      <td>0.520365</td>\n",
       "      <td>1</td>\n",
       "      <td>0.865104</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>giny</td>\n",
       "      <td>829.985152</td>\n",
       "      <td>8.416720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_columntransformer__tfidf_evidence__max_features  \\\n",
       "2                                               5000      \n",
       "0                                               4000      \n",
       "3                                               None      \n",
       "1                                               6000      \n",
       "4                                               2000      \n",
       "\n",
       "  param_columntransformer__tfidf_evidence__ngram_range  \\\n",
       "2                                             (1, 1)     \n",
       "0                                             (1, 2)     \n",
       "3                                             (1, 1)     \n",
       "1                                             (2, 2)     \n",
       "4                                             (1, 1)     \n",
       "\n",
       "  param_columntransformer__tfidf_evidence__use_idf  \\\n",
       "2                                             True   \n",
       "0                                             True   \n",
       "3                                             True   \n",
       "1                                            False   \n",
       "4                                             True   \n",
       "\n",
       "  param_columntransformer__tfidf_evidence__norm  \\\n",
       "2                                            l1   \n",
       "0                                            l2   \n",
       "3                                            l1   \n",
       "1                                            l2   \n",
       "4                                            l2   \n",
       "\n",
       "  param_randomforestclassifier__criterion  mean_fit_time  std_fit_time  \\\n",
       "2                                 entropy     871.215560      8.144630   \n",
       "0                                 entropy     916.800501      5.654871   \n",
       "3                                 entropy    1152.113806     17.604980   \n",
       "1                                 entropy     897.049993      6.941904   \n",
       "4                                    giny     829.985152      8.416720   \n",
       "\n",
       "   mean_test_neg_log_loss  std_test_neg_log_loss  rank_test_neg_log_loss  \\\n",
       "2               -1.688463               0.075811                       1   \n",
       "0               -1.723829               0.192871                       2   \n",
       "3               -1.769758               0.136692                       3   \n",
       "1               -1.784257               0.101149                       4   \n",
       "4                     NaN                    NaN                       5   \n",
       "\n",
       "   mean_test_accuracy  rank_test_accuracy  mean_test_f1_macro  \\\n",
       "2            0.643665                   1            0.505800   \n",
       "0            0.637632                   3            0.506809   \n",
       "3            0.633107                   4            0.493645   \n",
       "1            0.642911                   2            0.520365   \n",
       "4                 NaN                   5                 NaN   \n",
       "\n",
       "   rank_test_f1_macro  mean_test_roc_auc_ovr  rank_test_roc_auc_ovr  \n",
       "2                   3               0.860355                      3  \n",
       "0                   2               0.876764                      1  \n",
       "3                   4               0.859302                      4  \n",
       "1                   1               0.865104                      2  \n",
       "4                   5                    NaN                      5  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_evaluate = [\"param_columntransformer__tfidf_evidence__max_features\",\n",
    "                      \"param_columntransformer__tfidf_evidence__ngram_range\",\n",
    "                      \"param_columntransformer__tfidf_evidence__use_idf\",\n",
    "                      \"param_columntransformer__tfidf_evidence__norm\",\n",
    "                      \"param_randomforestclassifier__criterion\"]\n",
    "RF_res = save_results(rs_RF,params_to_evaluate)\n",
    "RF_res.sort_values(by='mean_test_neg_log_loss',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados\n",
    "RF_res.to_csv('RF.csv')\n",
    "\n",
    "# Testing\n",
    "add_res(rs_RF,'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf4 = SVC(probability=True)\n",
    "parameters = {\n",
    "    'columntransformer__tfidf_evidence__ngram_range': ((1, 1),(2, 2),(1,2)),\n",
    "    'columntransformer__tfidf_evidence__use_idf': (True, False),\n",
    "    'columntransformer__tfidf_evidence__max_features': (1000,2000,3000,4000,5000,6000,7000,8000,9000,None),\n",
    "    'columntransformer__tfidf_evidence__norm': ('l1', 'l2'),\n",
    "    'svc__kernel':('linear','rbf','sigmoid','poly')\n",
    " }\n",
    "pipeline4 = create_pipeline(clf4)\n",
    "rs_SVC = create_rscv(pipeline4,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 296.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=333, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(remainder='passthrough',\n",
       "                                                                transformers=[('binarizado_gene',\n",
       "                                                                               OneHotEncoder(dtype='int',\n",
       "                                                                                             handle_unknown='ignore'),\n",
       "                                                                               ['Gene']),\n",
       "                                                                              ('tfidf_evidence',\n",
       "                                                                               TfidfVectorizer(stop_words={'a',\n",
       "                                                                                                           'about',\n",
       "                                                                                                           'abov',\n",
       "                                                                                                           'above',\n",
       "                                                                                                           'after',\n",
       "                                                                                                           'after...\n",
       "                                                                                            9000,\n",
       "                                                                                            None),\n",
       "                                        'columntransformer__tfidf_evidence__ngram_range': ((1,\n",
       "                                                                                            1),\n",
       "                                                                                           (2,\n",
       "                                                                                            2),\n",
       "                                                                                           (1,\n",
       "                                                                                            2)),\n",
       "                                        'columntransformer__tfidf_evidence__norm': ('l1',\n",
       "                                                                                    'l2'),\n",
       "                                        'columntransformer__tfidf_evidence__use_idf': (True,\n",
       "                                                                                       False),\n",
       "                                        'svc__kernel': ('linear', 'rbf',\n",
       "                                                        'sigmoid', 'poly')},\n",
       "                   random_state=333, refit='neg_log_loss',\n",
       "                   scoring=['neg_log_loss', 'accuracy', 'f1_macro',\n",
       "                            'roc_auc_ovr'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_SVC.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_columntransformer__tfidf_evidence__max_features</th>\n",
       "      <th>param_columntransformer__tfidf_evidence__use_idf</th>\n",
       "      <th>param_columntransformer__tfidf_evidence__ngram_range</th>\n",
       "      <th>param_columntransformer__tfidf_evidence__norm</th>\n",
       "      <th>param_svc__kernel</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "      <th>rank_test_neg_log_loss</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "      <th>mean_test_roc_auc_ovr</th>\n",
       "      <th>rank_test_roc_auc_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>l2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1085.558751</td>\n",
       "      <td>1.146183</td>\n",
       "      <td>-1.029789</td>\n",
       "      <td>0.009968</td>\n",
       "      <td>1</td>\n",
       "      <td>0.634992</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500990</td>\n",
       "      <td>3</td>\n",
       "      <td>0.889370</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>l2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>989.852848</td>\n",
       "      <td>13.765539</td>\n",
       "      <td>-1.034687</td>\n",
       "      <td>0.010845</td>\n",
       "      <td>2</td>\n",
       "      <td>0.632730</td>\n",
       "      <td>2</td>\n",
       "      <td>0.495277</td>\n",
       "      <td>5</td>\n",
       "      <td>0.890712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>l2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>921.367400</td>\n",
       "      <td>6.774758</td>\n",
       "      <td>-1.035005</td>\n",
       "      <td>0.012670</td>\n",
       "      <td>3</td>\n",
       "      <td>0.631599</td>\n",
       "      <td>3</td>\n",
       "      <td>0.495362</td>\n",
       "      <td>4</td>\n",
       "      <td>0.887268</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>l2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2513.720478</td>\n",
       "      <td>155.218383</td>\n",
       "      <td>-1.044673</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>4</td>\n",
       "      <td>0.631599</td>\n",
       "      <td>3</td>\n",
       "      <td>0.502675</td>\n",
       "      <td>2</td>\n",
       "      <td>0.888048</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>l2</td>\n",
       "      <td>linear</td>\n",
       "      <td>1251.142795</td>\n",
       "      <td>11.898674</td>\n",
       "      <td>-1.055133</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>5</td>\n",
       "      <td>0.625943</td>\n",
       "      <td>5</td>\n",
       "      <td>0.535414</td>\n",
       "      <td>1</td>\n",
       "      <td>0.884747</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_columntransformer__tfidf_evidence__max_features  \\\n",
       "2                                               9000      \n",
       "5                                               2000      \n",
       "0                                               1000      \n",
       "9                                               None      \n",
       "4                                               9000      \n",
       "\n",
       "  param_columntransformer__tfidf_evidence__use_idf  \\\n",
       "2                                            False   \n",
       "5                                             True   \n",
       "0                                            False   \n",
       "9                                             True   \n",
       "4                                             True   \n",
       "\n",
       "  param_columntransformer__tfidf_evidence__ngram_range  \\\n",
       "2                                             (2, 2)     \n",
       "5                                             (2, 2)     \n",
       "0                                             (2, 2)     \n",
       "9                                             (1, 2)     \n",
       "4                                             (1, 2)     \n",
       "\n",
       "  param_columntransformer__tfidf_evidence__norm param_svc__kernel  \\\n",
       "2                                            l2               rbf   \n",
       "5                                            l2               rbf   \n",
       "0                                            l2               rbf   \n",
       "9                                            l2               rbf   \n",
       "4                                            l2            linear   \n",
       "\n",
       "   mean_fit_time  std_fit_time  mean_test_neg_log_loss  std_test_neg_log_loss  \\\n",
       "2    1085.558751      1.146183               -1.029789               0.009968   \n",
       "5     989.852848     13.765539               -1.034687               0.010845   \n",
       "0     921.367400      6.774758               -1.035005               0.012670   \n",
       "9    2513.720478    155.218383               -1.044673               0.007975   \n",
       "4    1251.142795     11.898674               -1.055133               0.005250   \n",
       "\n",
       "   rank_test_neg_log_loss  mean_test_accuracy  rank_test_accuracy  \\\n",
       "2                       1            0.634992                   1   \n",
       "5                       2            0.632730                   2   \n",
       "0                       3            0.631599                   3   \n",
       "9                       4            0.631599                   3   \n",
       "4                       5            0.625943                   5   \n",
       "\n",
       "   mean_test_f1_macro  rank_test_f1_macro  mean_test_roc_auc_ovr  \\\n",
       "2            0.500990                   3               0.889370   \n",
       "5            0.495277                   5               0.890712   \n",
       "0            0.495362                   4               0.887268   \n",
       "9            0.502675                   2               0.888048   \n",
       "4            0.535414                   1               0.884747   \n",
       "\n",
       "   rank_test_roc_auc_ovr  \n",
       "2                      2  \n",
       "5                      1  \n",
       "0                      4  \n",
       "9                      3  \n",
       "4                      5  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_evaluate = [\"param_columntransformer__tfidf_evidence__max_features\",\n",
    "                      \"param_columntransformer__tfidf_evidence__use_idf\",\n",
    "                      \"param_columntransformer__tfidf_evidence__ngram_range\",\n",
    "                      \"param_columntransformer__tfidf_evidence__norm\",\n",
    "                      \"param_svc__kernel\"]\n",
    "SVC_res = save_results(rs_SVC,params_to_evaluate)\n",
    "SVC_res.sort_values(by='mean_test_neg_log_loss',ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos los resultados\n",
    "SVC_res.to_csv('SVC.csv')\n",
    "\n",
    "# Testing\n",
    "add_res(rs_SVC,'SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB_M</td>\n",
       "      <td>1.220770</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>0.259952</td>\n",
       "      <td>0.845683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>1.603281</td>\n",
       "      <td>0.623494</td>\n",
       "      <td>0.545862</td>\n",
       "      <td>0.860197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1.002137</td>\n",
       "      <td>0.641566</td>\n",
       "      <td>0.500013</td>\n",
       "      <td>0.885254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clf  log_loss  accuracy  f1-macro       ROC\n",
       "0  NB_M  1.220770  0.530120  0.259952  0.845683\n",
       "1    RF  1.603281  0.623494  0.545862  0.860197\n",
       "2   SVC  1.002137  0.641566  0.500013  0.885254"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exportamos resultados totales\n",
    "df_results.to_csv('df_rs.csv')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
